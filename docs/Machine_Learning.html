

<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="ipynb_website:version" content="0.9.6" />
<meta name="viewport" content="width=device-width, initial-scale=1" />

<title>Nathaniel Dake Blog</title>
<script type="text/javascript" src="https://ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
<script type="text/javascript" src="https://ajax.googleapis.com/ajax/libs/jqueryui/1.9.1/jquery-ui.min.js"></script>
<link href="site_libs/bootstrap-3.3.5/css/readable.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<link href="site_libs/font-awesome-4.5.0/css/font-awesome.min.css" rel="stylesheet" />

<style type="text/css">code{white-space: pre;}</style>
<link rel="stylesheet"
      href="site_libs/highlightjs/null.min.css"
      type="text/css" />

<script src="site_libs/highlightjs/highlight.pack.js"></script>
<script>hljs.initHighlightingOnLoad();</script>
<script type="text/javascript">
if (window.hljs && document.readyState && document.readyState === "complete") {
   window.setTimeout(function() {
      hljs.initHighlighting();
   }, 0);
}
</script>
<style type="text/css">
  div.input_prompt {display: none;}
  div.output_html {
     font-family: "PT Mono", monospace;
     font-size: 10.0pt;
     color: #353535;
     padding-bottom: 25px;
 }
  pre:not([class]) {
    background-color: white;
  }
</style>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML"></script>
<script>
    MathJax.Hub.Config({
        extensions: ["tex2jax.js"],
        jax: ["input/TeX", "output/HTML-CSS"],
        tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        displayMath: [ ['$$','$$'] ["\\[","\\]"] ],
        processEscapes: true
        },
        "HTML-CSS": {
            preferredFont: "TeX",
            availableFonts: ["TeX"],
            styles: {
                scale: 110,
                ".MathJax_Display": {
                    "font-size": "110%",
                }
            }
        }
    });
</script>

</head>

<body>
<style type = "text/css">
@font-face {
 font-family: 'Droid Sans';
 font-weight: normal;
 font-style: normal;
 src: local('Droid Sans'), url('fonts/droid-sans.ttf') format('truetype');
}
@font-face {
 font-family: 'Fira Code';
 font-weight: normal;
 font-style: normal;
 src: local('Fira Code'), url('fonts/firacode.otf') format('opentype');
}
@font-face {
 font-family: 'PT Mono';
 font-weight: normal;
 font-style: normal;
 src: local('PT Mono'), url('fonts/ptmono.ttf') format('truetype');
}

body {
  font-family: "sans-serif";
  font-size: 160%;
  padding-top: 66px;
  padding-bottom: 40px;
}

h1, h2, h3, h4, h5, h6 {
  margin-top: 20px;
 }

p {
  text-align:justify;
  line-height:1.5;
  font-family:Helvetica,Arial,sans-serif;
  font-size:16px;
  font-weight:300
}

ul,ol {
  text-align:justify;
  line-height:1.5;
  font-family:Helvetica,Arial,sans-serif;
  font-size:16px;
  font-weight:500
}

ul ul,ol ul,ul ol,ol ol {
  text-align:justify;
  line-height:1.5;
  font-family:Helvetica,Arial,sans-serif;
  font-size:16px;
  font-weight:500
}

blockquote p {
  font-weight:450
}

a.anchor-link:link {
  text-decoration: none;
  padding: 0px 20px;
  visibility: hidden;
}

h1:hover .anchor-link,
h2:hover .anchor-link,
h3:hover .anchor-link,
h4:hover .anchor-link,
h5:hover .anchor-link,
h6:hover .anchor-link {
  visibility: hidden;
}

.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: #EEEEFF;
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>

<div class="container-fluid main-container">

<!-- tabsets -->
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->

<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Nathaniel Dake Blog</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        
<li>
  <a href="./Deep_Learning.html">Deep Learning</a>
</li>
        
<li>
  <a href="./Machine_Learning.html">Machine Learning</a>
</li>
        
<li>
  <a href="./Mathematics.html">Mathematics</a>
</li>
        
<li>
  <a href="./AI.html">AI</a>
</li>
        
<li>
  <a href="./NLP.html">NLP</a>
</li>
        
<li>
  <a href="./Books.html">Books</a>
</li>
        
      </ul>
    
<ul class="nav navbar-nav navbar-right">
<li>
   <a href="https://github.com/NathanielDake/nathanieldake.github.io"> source </a>
</li>
</ul>
        
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Machine-learning">Machine learning<a class="anchor-link" href="#Machine-learning">&#182;</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="4.-Unsupervised-Learning-Cluster-Analysis">4. Unsupervised Learning Cluster Analysis<a class="anchor-link" href="#4.-Unsupervised-Learning-Cluster-Analysis">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a href="Machine_Learning/04-Unsupervised_Learning_Cluster_Analysis-01-Cluster-Analysis-Introduction.html"><strong>1. Introduction</strong></a><br>
&nbsp; &nbsp;In the real world, you can imagine that you may not always have access to the optimal answer. Or, maybe there isn't an optimal or correct answer. You would want the robot to be able to explore things on its own, and learn things just by looking for patterns.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a href="Machine_Learning/04-Unsupervised_Learning_Cluster_Analysis-02-Cluster-Analysis-K-Means-Clustering.html"><strong>2. K-Means Clustering</strong></a><br>
&nbsp; &nbsp;We know that we are going to be trying to perform <strong>K-Means Clustering</strong> on data. So let's take a moment to visualize some data that we may get.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a href="Machine_Learning/04-Unsupervised_Learning_Cluster_Analysis-03-Cluster-Analysis-Hierarchical-Clustering.html"><strong>3. Hierarchical Clustering</strong></a><br>
&nbsp; &nbsp;We are now going to talk about a different technique for building clustering known as: <strong>Agglomerative Clustering</strong>. If you have ever studied algorithms, you will recognize this as a greedy algorithm. We are going to be purposefully short sighted, and make what appears to be the best decision at the time.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a href="Machine_Learning/04-Unsupervised_Learning_Cluster_Analysis-04-Cluster-Analysis-Gaussian-Mixture-Models.html"><strong>4. Gaussian Mixture Models</strong></a><br>
&nbsp; &nbsp;Gaussian Mixture Models are a form of <strong>density estimation</strong>. They give us an approximation of the probability distribution of our data. We want to use gaussian mixture models when we notice that our data is multimodal (meaning there are multiple modes or bumps). From probability, we can recall that the <strong>mode</strong> is just the most common value. For instance, a multi modal distribution can be seen below:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="5.-Hidden-Markov-Models">5. Hidden Markov Models<a class="anchor-link" href="#5.-Hidden-Markov-Models">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a href="Machine_Learning/05-Hidden_Markov_Models-01-Hidden-Markov-Models-Introduction.html"><strong>1. Hidden Markov Models Introduction</strong></a><br>
&nbsp; &nbsp;This post is going to cover <strong>hidden markov models</strong>, which are used for modeling sequences of data. Sequences appear everywhere, from stock prices, to language, credit scoring, webpage visits.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a href="Machine_Learning/05-Hidden_Markov_Models-02-Hidden-Markov-Models-Markov-Models.html"><strong>2. Markov Models and The Markov Property</strong></a><br>
&nbsp; &nbsp;What is the markov property?</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a href="Machine_Learning/05-Hidden_Markov_Models-03-Markov-Models-Example-Problems-and-Applications.html"><strong>3. Markov Models Example Problems</strong></a><br>
&nbsp; &nbsp;We will now look at a model that examines our state of healthiness vs. being sick. Keep in mind that this is very much like something you could do in real life. If you wanted to model a certain situation or environment, we could take some data that we have gathered, build a maximum likelihood model on it, and do things like study the properties that emerge from the model, or make predictions from the model, or generate the next most likely state.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a href="Machine_Learning/05-Hidden_Markov_Models-04-Hidden-Markov-Models-Hidden-Markov-Models-Discrete-Observations.html"><strong>4. From Markov Models to Hidden Markov Models</strong></a><br>
&nbsp; &nbsp;We are now going to extend the basic idea of markov models to hidden markov models. We have talked about latent variables before, and they will be a very important concept as we move forward. They show up in <strong>K-means clustering</strong>, <strong>Gaussian Mixture Models</strong>, <strong>principle components analysis</strong>, and many other areas. With hidden markov models, it even shows up in the name, so you know that hidden (latent) variables are central to this model.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a href="Machine_Learning/05-Hidden_Markov_Models-05-Hidden-Markov-Models-HMM-Calculations.html"><strong>5. Hidden Markov Model Calculations</strong></a><br>
&nbsp; &nbsp;This appendix serves as an accompaniment to hidden markov models, discrete observations. We will go over calculations concerning:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a href="Machine_Learning/05-Hidden_Markov_Models-06-Hidden-Markov-Models-Hidden-Markov-Models-Discrete-Observations-Deep-Learning-Libraries.html"><strong>6. Hidden Markov Models with Theano and TensorFlow</strong></a><br>
&nbsp; &nbsp;In the last section we went over the training and prediction procedures of Hidden Markov Models. This was all done using only vanilla numpy the Expectation Maximization algorithm. I now want to introduce how both <code>Theano</code> and <code>Tensorflow</code> can be utilized to accomplish the same goal, albeit by a very different process.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a href="Machine_Learning/05-Hidden_Markov_Models-07-Hidden-Markov-Models-Continuous-Observations.html"><strong>7. HMM's with Continuous Observations</strong></a><br>
&nbsp; &nbsp;At this point we are ready to look at the use application of Hidden Markov Model's to discrete observations. All that is meant by continuous observations is that what you observe is a number on a scale, rather than a symbol such as heads or tails, or words. This is an interesting topic in and of itself, because it allows us to think about:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a href="Machine_Learning/05-Hidden_Markov_Models-08-Hidden-Markov-Models-Applications.html"><strong>8. HMM Applications</strong></a><br>
&nbsp; &nbsp;We have now covered the vast majority of the theory related to HMM's. We have seen how they model the probability of a sequence, and can handle when those sequences deal with latent states. Additionally we saw how they can be extended to deal with continuous observations by incorporating the concept of a gaussian mixture model in place of the $B$ emission matrix. I want to take a post to go over a few different real world applications of HMM's and leave you with a few ideas of what else is possible.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="6.-Ensemble-methods">6. Ensemble methods<a class="anchor-link" href="#6.-Ensemble-methods">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a href="Machine_Learning/06-Ensemble_methods-01-Bias-Variance-Trade-Off .html"><strong>1. Bias-Variance Trade-Off</strong></a><br>
&nbsp; &nbsp;As we get started with ensemble methods, we will being by looking at the <strong>bias-variance trade-off</strong>. There are three key terms in particular that we are going to look at:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a href="Machine_Learning/06-Ensemble_methods-02-Bias-Variance-Regression-Demo.html"><strong>2. Bias-Variance Regression Demo</strong></a><br>
&nbsp; &nbsp;Let's take a moment to start from the beginning. In any data generating process, we have what is a called a <strong>ground truth function</strong>, which we will call:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a href="Machine_Learning/06-Ensemble_methods-03-Bootstrap-Estimates-and-Bagging.html"><strong>3. Bootstrap Estimation</strong></a><br>
&nbsp; &nbsp;We previously looked at the bias-variance tradeoff and if you were thinking critically you may have wondered: "Could it be possible in some way to lower bias and variance simultaneously?"</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a href="Machine_Learning/06-Ensemble_methods-04-Random-Forest.html"><strong>4. Random Forest Algorithm</strong></a><br>
&nbsp; &nbsp;We are now going to touch on the <strong>random forest</strong> algorithm, which touches on earlier concepts we have gone over.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a href="Machine_Learning/06-Ensemble_methods-05-AdaBoost.html"><strong>5. AdaBoost Algorithm</strong></a><br>
&nbsp; &nbsp;We are now going to talk about <strong>boosting</strong>, and introduce a realization of the boosting idea, the algorithm <strong>AdaBoost</strong>. It is currently still one of the most powerful ensemble methods in existence, and like the random forest it is considered a good off the shelf/plug and play model.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a href="Machine_Learning/06-Ensemble_methods-06-Summary-of-Concepts.html"><strong>6. Summary</strong></a><br>
&nbsp; &nbsp;We started off this series talking about the bias-variance trade-off. We showed that the error of any classification or regression model is a combination of <strong>bias</strong>, <strong>variance</strong>, and <strong>irreducible error</strong>. We then demonstrated that irreducible error can't be reduced, by bias and variance can! In the ideal situation both bias and variance are <strong>low</strong>. The main dilemma we saw was that as we decrease one, the other tends to increase. So, the idea that we found was that we want to find a happy medium where we are optimizing the test error. We learned than ensemble methods are a way to make the tradeoff, less of a tradeoff (i.e. attain low bias and low variance)!</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="7.-Dimensionality-Reduction">7. Dimensionality Reduction<a class="anchor-link" href="#7.-Dimensionality-Reduction">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a href="Machine_Learning/07-Dimensionality_Reduction-PCA.html"><strong>1. Dimensionality Reduction &amp; Principal Component Analysis</strong></a><br>
&nbsp; &nbsp;Principal component analysis is an incredibly powerful technique that all data scientists should be aware of in the plight against the <strong>curse of dimensionality</strong>. Before we dig into the mechanics of it, however, we need to define what the curse of dimensionality is to begin with.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="8.-Bayesian-Machine-Learning">8. Bayesian Machine Learning<a class="anchor-link" href="#8.-Bayesian-Machine-Learning">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a href="Machine_Learning/08-Bayesian_Machine_Learning-01-Bayesian-Inference.html"><strong>1. Bayesian Inference</strong></a><br>
&nbsp; &nbsp;So, you want to know about <strong>Bayesian Techniques</strong> and how they are utilized in Machine Learning? Maybe you have head about the <strong>Causal Revoluation</strong> and want to get a better understanding of the role these techniques played in getting there? Or, you have determined that your problem would be best solved Bayesian A/B Testing? Whatever your reasoning, you have come to the right place. However, before we dissect the techniques listed above, and many others, we need to determine two things:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a href="Machine_Learning/08-Bayesian_Machine_Learning-02-Bayesian-AB-Testing.html"><strong>2. Bayesian A/B Testing</strong></a><br>
&nbsp; &nbsp;In this post we are going to discuss Bayesian Methods and their application to Bayesian A/B testing. In particular we will:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a href="Machine_Learning/08-Bayesian_Machine_Learning-03-Bayes-Classifiers.html"><strong>3. Bayes Classifiers</strong></a><br>
&nbsp; &nbsp;This is an article that I have been excited to write for quite some time! While the model and classification techniques are nothing new, Naive Bayes (and Bayes Nets generalizations) build upon all of the intuitions that I have laid out in past posts on probability theory, classic frequentist statistical inference, and bayesian inference. I highly recommend that you take some time to read them over if your background in <a href="../Mathematics/04-Statistics-01-Introduction.html">statistics</a>, <a href="../Mathematics/03-Probability-01-Introduction.html">probability</a>, and <a href="./08-Bayesian_Machine_Learning-01-Bayesian-Inference.html">bayesian inference</a> is rusty (I will particularly be assuming the reader is comfortable with bayesian inference).</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="9.-Time-Series-Forecasting">9. Time Series Forecasting<a class="anchor-link" href="#9.-Time-Series-Forecasting">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a href="Machine_Learning/09-Time_Series_Forecasting-01-overview.html"><strong>1. Time Series in Pandas</strong></a><br>
&nbsp; &nbsp;If you have been following along with my posts you may have realized that something I hadn't spent a lot of time dealing with was time series and subsequent forecasting. I have dealt with sequences (both via Recurrent Neural Networks and Markov Models), but given vast amount of time series data that you can encounter in industry, this post is long over due.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a href="Machine_Learning/09-Time_Series_Forecasting-02-analysis.html"><strong>2. Time Series Analysis</strong></a><br>
&nbsp; &nbsp;I want us to now move on to learning about the main tool we will use in time series forecasting: the <code>Statsmodels</code> library. Statsmodels can be thoughts of as follow:</p>

</div>
</div>
</div>
<hr>
&copy; 2018 Nathaniel Dake
<!-- To enable disqus, uncomment the section below and provide your disqus_shortname -->

</div>

<script>
// add bootstrap table styles to pandoc tables
$(document).ready(function () {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>
</html>
