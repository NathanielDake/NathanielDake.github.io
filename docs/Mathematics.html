<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="ipynb_website:version" content="0.9.6" />
<meta name="viewport" content="width=device-width, initial-scale=1" />

<title>Nathaniel Dake Blog</title>
<script type="text/javascript" src="https://ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
<script type="text/javascript" src="https://ajax.googleapis.com/ajax/libs/jqueryui/1.9.1/jquery-ui.min.js"></script>
<link href="site_libs/bootstrap-3.3.5/css/readable.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<link href="site_libs/font-awesome-4.5.0/css/font-awesome.min.css" rel="stylesheet" />

<style type="text/css">code{white-space: pre;}</style>
<link rel="stylesheet"
      href="site_libs/highlightjs/null.min.css"
      type="text/css" />

<script src="site_libs/highlightjs/highlight.pack.js"></script>
<script>hljs.initHighlightingOnLoad();</script>
<script type="text/javascript">
if (window.hljs && document.readyState && document.readyState === "complete") {
   window.setTimeout(function() {
      hljs.initHighlighting();
   }, 0);
}
</script>
<style type="text/css">
  div.input_prompt {display: none;}
  div.output_html {
     font-family: "PT Mono", monospace;
     font-size: 10.0pt;
     color: #353535;
     padding-bottom: 25px;
 }
  pre:not([class]) {
    background-color: white;
  }
</style>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML"></script>
<script>
    MathJax.Hub.Config({
        extensions: ["tex2jax.js"],
        jax: ["input/TeX", "output/HTML-CSS"],
        tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        displayMath: [ ['$$','$$'] ["\\[","\\]"] ],
        processEscapes: true
        },
        "HTML-CSS": {
            preferredFont: "TeX",
            availableFonts: ["TeX"],
            styles: {
                scale: 110,
                ".MathJax_Display": {
                    "font-size": "110%",
                }
            }
        }
    });
</script>

</head>

<body>
<style type = "text/css">
@font-face {
 font-family: 'Droid Sans';
 font-weight: normal;
 font-style: normal;
 src: local('Droid Sans'), url('fonts/droid-sans.ttf') format('truetype');
}
@font-face {
 font-family: 'Fira Code';
 font-weight: normal;
 font-style: normal;
 src: local('Fira Code'), url('fonts/firacode.otf') format('opentype');
}
@font-face {
 font-family: 'PT Mono';
 font-weight: normal;
 font-style: normal;
 src: local('PT Mono'), url('fonts/ptmono.ttf') format('truetype');
}

body {
  font-family: "Spectral-Light";
  font-size: 160%;
  padding-top: 66px;
  padding-bottom: 40px;
}

h1, h2, h3, h4, h5, h6 {
  margin-top: 20px;
 }

p {
  text-align:justify;
  line-height:1.5;
  font-family:Helvetica,Arial,sans-serif;
  font-size:16px;
  font-weight:300
}

ul,ol {
  text-align:justify;
  line-height:1.5;
  font-family:Helvetica,Arial,sans-serif;
  font-size:16px;
  font-weight:500
}

ul ul,ol ul,ul ol,ol ol {
  text-align:justify;
  line-height:1.5;
  font-family:Helvetica,Arial,sans-serif;
  font-size:16px;
  font-weight:500
}

blockquote p {
  font-weight:450
}

a.anchor-link:link {
  text-decoration: none;
  padding: 0px 20px;
  visibility: hidden;
}

h1:hover .anchor-link,
h2:hover .anchor-link,
h3:hover .anchor-link,
h4:hover .anchor-link,
h5:hover .anchor-link,
h6:hover .anchor-link {
  visibility: hidden;
}

.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: #EEEEFF;
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>

<div class="container-fluid main-container">

<!-- tabsets -->
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->

<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Nathaniel Dake Blog</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        
<li>
  <a href="./Deep_Learning.html">Deep Learning</a>
</li>
        
<li>
  <a href="./Machine_Learning.html">Machine Learning</a>
</li>
        
<li>
  <a href="./Mathematics.html">Mathematics</a>
</li>
        
<li>
  <a href="./AI.html">AI</a>
</li>
        
<li>
  <a href="./NLP.html">NLP</a>
</li>
        
      </ul>
    
<ul class="nav navbar-nav navbar-right">
<li>
   <a href="https://github.com/NathanielDake/nathanieldake.github.io"> source </a>
</li>
</ul>
        
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Mathematics">Mathematics<a class="anchor-link" href="#Mathematics">&#182;</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="1.-Calculus">1. Calculus<a class="anchor-link" href="#1.-Calculus">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a href="Mathematics/01-Calculus-01-Fundamental-Theorem-of-Calculus.html"><strong>1. The Fundamental Theorem of Calculus</strong></a><br>
&nbsp; &nbsp;All across the field of Machine Learning calculus is utilized. In the world of Deep Learning, optimization via backpropagation reigns supreme, and it is often easy to end up either letting the computer handle all of the derivation and integration for you, or to forget the underlying intuition of what the equations mean in english.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="2.-Linear-Algebra">2. Linear Algebra<a class="anchor-link" href="#2.-Linear-Algebra">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a href="Mathematics/02-Linear_Algebra-01-Introduction.html"><strong>1. Linear Algebra Introduction</strong></a><br>
&nbsp; &nbsp;Linear algebra is frequently utilized in the implementation of machine learning algorithms, so it is very important to have an intuitive understanding of what it represents and how it is used. I recommend looking at this along side of my numpy walkthrough in the math appendix.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a href="Mathematics/02-Linear_Algebra-02-Linear-Combination-Linear-Transformation-Dot-Product.html"><strong>2. Linear Combination, Linear Transformation, Dot Product</strong></a><br>
&nbsp; &nbsp;As we progress in our understanding of the math surrounding machine learning, AI, and DS, there will be a host of linear algebra concepts that we are forced to reckon with. From PCA and it's utilization of eigenvalues and eigenvectors, to neural networks reliance on linear combinations and matrix multiplication, the list goes on and on. Having a very solid grasp on linear algebra is crucial to realizing <em>how</em> and <em>why</em> these algorithms work.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a href="Mathematics/02-Linear_Algebra-03-Determinant-Inverse-Matrices-Cross-Product.html"><strong>3. The Determinant, Linear Systems Of Equations &amp; Inverse Matrices</strong></a><br>
&nbsp; &nbsp;Recall that when we discussed linear transformations, some will stretch space out, while others squish it on in:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="3.-Probability">3. Probability<a class="anchor-link" href="#3.-Probability">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a href="Mathematics/03-Probability-01-Introduction.html"><strong>1. Introduction to Probability Theory</strong></a><br>
&nbsp; &nbsp;This is a post that I have been excited to get to for over a year now. Probability theory plays an incredibly interesting and unique role in the studying of machine learning and articiail intelligence techniques. It gives us a wonderful way of dealing with <strong>uncertainty</strong>, and shows up in everything from <strong>Hidden Markov Models</strong>, <strong>Bayesian Networks</strong>, <strong>Causal Path Analysis</strong>, <strong>Bayesian A/B</strong> testing, and many other areas.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a href="Mathematics/03-Probability-02-Bayes-Rule.html"><strong>2. Bayes Rule</strong></a><br>
&nbsp; &nbsp;The main goal of this post is to dig a bit further into Bayes rule, from a purely probabilistic perspective! Before we begin I do want to make one note; a great deal of the power of Bayes Rule comes in the form of bayesian inference and bayesian statistics, which can be found in the statistics section. I would recommend reading both of those posts as well if you are interested, since they demonstrate the application of Bayes rule to real world problems. If you have caught the bayesian bug at that point then I recommend reading my posts on Bayesian AB testing, found in the Machine Learning section.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a href="Mathematics/03-Probability-03-Inequalities.html"><strong>3. Probability Inequalities</strong></a><br>
&nbsp; &nbsp;Probability inequality play a large role in determining an answer to the crucial question: Is learning feasible? Of course in this context I am referring to statistical/machine learning. You may think to yourself: "Of course it is possible! We constantly here about wonderful new algorithms and ML techniques created, computer vision systems, natural language understanding virtual assistants-many of which are discussed in depth in this blog!". In this you are most certainly correct.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a href="Mathematics/03-Probability-04-Histograms-vs-pdfs-vs-cdfs.html"><strong>4. Histogram vs. PDF vs. CDF</strong></a><br>
&nbsp; &nbsp;This post is TODO.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="4.-Statistics">4. Statistics<a class="anchor-link" href="#4.-Statistics">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a href="Mathematics/04-Statistics-01-Introduction.html"><strong>1. Introduction to Statistics</strong></a><br>
&nbsp; &nbsp;I have been meaning to get to an introductory statistics post for quite some time now! Statistics play an incredibly important role in modern day machine learning. For instance, while it is a far less "sexy" description, modern day machine learning can most often be reduced to variations of <strong>statistical learning</strong>, where as <strong>statistical model</strong> can be defined as follows:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a href="Mathematics/04-Statistics-02-History-of-Normal-Distribution.html"><strong>2. History of the Gaussian Distribution</strong></a><br>
&nbsp; &nbsp;If you have read any of my other posts, worked with statistics/probability, or any sort of machine learning, there is a very good chance that you have come across the <strong>Gaussian Distribution</strong>. The gaussian distribution, also known as the <strong>Normal Distribution</strong>, has an incredibly large range of uses; we will not talk about them here, however. For that I recommend looking through my other notebooks, digging into the <strong>Central Limit Theorem</strong>, <strong>sampling</strong>, <strong>Gaussian Mixture Models</strong>, distributions in the social sciences, <strong>hypothesis testing</strong>, and so on.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a href="Mathematics/04-Statistics-03-statistical-inference.html"><strong>3. Statistical Inference and Frequentist A/B Testing</strong></a><br>
&nbsp; &nbsp;If you went through my <strong>Introduction to Statistics</strong> post, then you are finally arriving at the payoff for all of our work: <strong>statistical inference</strong>. Statistical inference is used a wide variety of ways, but for now we will informally describe it as follows:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a href="Mathematics/04-Statistics-04-non-parametric-tests-kolmogorov-smirnov-test.html"><strong>4. Non Parametric Hypothesis Testing: KS-Score</strong></a><br>
&nbsp; &nbsp;Generally in introductory statistics courses students are taught hypothesis testing via the students $t$ and the chi-squared tests. This doesn't inherently pose a problem, but in practice these tests involve many assumptions and conditions to be met and it leaves many students memorizing a set of steps to a method that can only be applied in very specific conditions. If those conditions change, then the student is either lost, or even worse, left applying an inappropriate and even misleading method.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a href="Mathematics/04-Statistics-05-limitations-of-clt-and-loln.html"><strong>5. Limitations of Law of Large Numbers and Central Limit Theorem</strong></a><br>
&nbsp; &nbsp;Let's dig in to areas where the Central limit Theorem and Law of Large numbers break down.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="5.-Information-Theory">5. Information Theory<a class="anchor-link" href="#5.-Information-Theory">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a href="Mathematics/05-Information_Theory-01-Cross-Entropy-and-MLE-walkthrough.html"><strong>1. Cross Entropy and Maximum Likelihood Estimation</strong></a><br>
&nbsp; &nbsp;If you have gone through any of my other walkthroughs on machine learning, particularly those on <strong>Logistic Regression</strong>, <strong>Neural Networks</strong>, <strong>Decision Trees</strong>, or <strong>Bayesian machine learning</strong> you have definitely come across the concept of <strong>Cross Entropy</strong> and <strong>Maximum Likelihood Estimation</strong>. Now, when discussed separately, these are relatively simple concepts to understand. However, during the creation of these notebooks, particularly the sections on logisitic regression and neural networks (and the cost functions involved), I felt as though it was not clear why they were related in certain cases.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="6.-Functions">6. Functions<a class="anchor-link" href="#6.-Functions">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a href="Mathematics/06-Functions-01-Composition-of-functions.html"><strong>1. Composition of Functions</strong></a><br>
&nbsp; &nbsp;This is a post that I have been excited to write for some time now. I realize that if you are reading this blog you most likely already have good handle on what a <strong>function</strong> is; both in the context's of mathematics and computer science. However, I recently saw just how shallow my own understanding was during my quest to understand the history of the <strong>normal distribution</strong>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a href="Mathematics/06-Functions-02-Inverse-functions-exponentials-and-logarithms.html"><strong>2. Exploring Inverse Functions, Exponentials, and Logarithms</strong></a><br>
&nbsp; &nbsp;Throughout fields ranging from mathematics and computer science, to physics and engineering, as well as economics and biology, frequently you will into the concept of the <strong>exponential</strong> and the <strong>logarithm</strong>. Often you may have memorized these concepts years ago, committed the rules for manipulating them to memory, and then simply treated them with an axiomatic esteem; they are felt to be <em>fundamental givens</em> rather than derivable from lower level principles. As with many things, this generally presents no problem. For instance, if I asked to you to simplify the following expression:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="7.-Probability-Theory,-The-Logic-of-Science">7. Probability Theory, The Logic of Science<a class="anchor-link" href="#7.-Probability-Theory,-The-Logic-of-Science">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a href="Mathematics/07-Probability_Theory,_The_Logic_of_Science-01-Chapter-1.html"><strong>1. Chapter 1 - Plausible Reasoning</strong></a><br>
&nbsp; &nbsp;As we tread further into the twenty first century, almost everyone is expected to memorize the mantra "we must make data driven decisions" (well, at least most people in the technology space, and certainly data scientists). However, I want us to pause for a moment and think about what that really means?</p>

</div>
</div>
</div>
<hr>
&copy; 2018 Nathaniel Dake
<!-- To enable disqus, uncomment the section below and provide your disqus_shortname -->

</div>

<script>
// add bootstrap table styles to pandoc tables
$(document).ready(function () {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>
</html>
