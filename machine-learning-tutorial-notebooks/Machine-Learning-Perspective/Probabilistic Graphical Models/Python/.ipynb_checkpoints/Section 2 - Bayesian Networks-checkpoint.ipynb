{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Models\n",
    "We are now going to dig further into a specific type of **Probabilistic Graphical Model**, specifically **Bayesian Networks**. We will discuss the following:\n",
    "1. What are Bayesian Models\n",
    "2. Independencies in Bayesian Networks\n",
    "3. How is Bayesian Model encoding the Joint Distribution\n",
    "4. How we do inference from Bayesian models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. What are Bayesian Models? \n",
    "A Bayesian Network is a probabilistic graphical model (a type of statistical model) that represents a set of **random variables** and their **conditional dependencies** via a **directed acyclic graph** (DAG). Bayesian networks are often used when we want to represent *causal relationships* between the random variables. They are parameterized by using **Conditional Probability Distributions** (CPD). Each node in the network is parameterized using:\n",
    "\n",
    "#### $$P(node|Pa(node))$$\n",
    "Where $Pa(node)$ represents the parents of the nodes in the network. We can dig into this further by looking at the following student model:\n",
    "\n",
    "<img src=\"images/student_full_param.png\">\n",
    "\n",
    "If we the use the library **pgmpy**, then we create the above model as follows:\n",
    "> 1. Define network structure (or learn it from data)\n",
    "2. Define CPD's between nodes (random variables)\n",
    "3. Associated CPD's with structure\n",
    "\n",
    "We can see this implemented below.\n",
    "\n",
    "### 1.1 Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports needed from pgmpy\n",
    "from pgmpy.models import BayesianModel\n",
    "from pgmpy.factors.discrete import TabularCPD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1 Set the Structure\n",
    "So, with our imports taken care of, we start by defining the model structure. We are able to define this by passing in a list of edges. Note, these edges are *directional*; for example, we have the tuple `(D, G)`, which means that `difficulty` influences `grade`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "student_model = BayesianModel([('difficulty', 'grade'), \n",
    "                       ('intelligence', 'grade'), \n",
    "                       ('grade', 'letter'), \n",
    "                       ('intelligence', 'sat')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2 Setup the relationships (CPDs)\n",
    "We then want to set up our relationshisp in the form of CPD's. A few things to note:\n",
    "> 1. `variable_card`: this is meant ot represent the number of discrete possibilities that the random variable can take on.\n",
    "2. `evidence`: this is referring to the parent of the random variable, i.e. $Pa(node)$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "difficulty_cpd = TabularCPD(variable='difficulty',\n",
    "                       variable_card=2,\n",
    "                       values=[[0.6, 0.4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "intelligence_cpd = TabularCPD(variable='intelligence',\n",
    "                              variable_card=2,\n",
    "                              values=[[0.7, 0.3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grade_cpd = TabularCPD(variable='grade', \n",
    "                       variable_card=3, \n",
    "                       values=[[0.3, 0.05, 0.9,  0.5],\n",
    "                               [0.4, 0.25, 0.08, 0.3],\n",
    "                               [0.3, 0.7,  0.02, 0.2]],\n",
    "                      evidence=['intelligence', 'difficulty'],\n",
    "                      evidence_card=[2, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "letter_cpd = TabularCPD(variable='letter', variable_card=2, \n",
    "                   values=[[0.1, 0.4, 0.99],\n",
    "                           [0.9, 0.6, 0.01]],\n",
    "                   evidence=['grade'],\n",
    "                   evidence_card=[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sat_cpd = TabularCPD(variable='sat', variable_card=2,\n",
    "                   values=[[0.95, 0.2],\n",
    "                           [0.05, 0.8]],\n",
    "                   evidence=['intelligence'],\n",
    "                   evidence_card=[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.3 Add the relationships (CPDs) to the Model\n",
    "The next step is to actually add our CPD's to our model. The way in whcih PGMPY specifies models is highly modular, which is great because it allows us to add and take away different CPD's very easily. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "student_model.add_cpds(difficulty_cpd, intelligence_cpd, grade_cpd, letter_cpd, sat_cpd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we can actually check our model for the network structure and CPDs and verifies that the CPDs are correctly defined and sum to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_model.check_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.4 Examine the Structure of the Graph\n",
    "We can see our model with the respective CPD's incorporated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<TabularCPD representing P(difficulty:2) at 0x110c828d0>,\n",
       " <TabularCPD representing P(intelligence:2) at 0x115c1e0b8>,\n",
       " <TabularCPD representing P(grade:3 | intelligence:2, difficulty:2) at 0x115c1e5c0>,\n",
       " <TabularCPD representing P(letter:2 | grade:3) at 0x115c1e438>,\n",
       " <TabularCPD representing P(sat:2 | intelligence:2) at 0x115c1e4e0>]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_model.get_cpds()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can examine specific nodes to ensure that the corresponding distributions are correct. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒══════════════╤═════╕\n",
      "│ difficulty_0 │ 0.6 │\n",
      "├──────────────┼─────┤\n",
      "│ difficulty_1 │ 0.4 │\n",
      "╘══════════════╧═════╛\n"
     ]
    }
   ],
   "source": [
    "print(student_model.get_cpds('difficulty'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒════════════════╤═════╕\n",
      "│ intelligence_0 │ 0.7 │\n",
      "├────────────────┼─────┤\n",
      "│ intelligence_1 │ 0.3 │\n",
      "╘════════════════╧═════╛\n"
     ]
    }
   ],
   "source": [
    "print(student_model.get_cpds('intelligence'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒══════════════╤════════════════╤════════════════╤════════════════╤════════════════╕\n",
      "│ intelligence │ intelligence_0 │ intelligence_0 │ intelligence_1 │ intelligence_1 │\n",
      "├──────────────┼────────────────┼────────────────┼────────────────┼────────────────┤\n",
      "│ difficulty   │ difficulty_0   │ difficulty_1   │ difficulty_0   │ difficulty_1   │\n",
      "├──────────────┼────────────────┼────────────────┼────────────────┼────────────────┤\n",
      "│ grade_0      │ 0.3            │ 0.05           │ 0.9            │ 0.5            │\n",
      "├──────────────┼────────────────┼────────────────┼────────────────┼────────────────┤\n",
      "│ grade_1      │ 0.4            │ 0.25           │ 0.08           │ 0.3            │\n",
      "├──────────────┼────────────────┼────────────────┼────────────────┼────────────────┤\n",
      "│ grade_2      │ 0.3            │ 0.7            │ 0.02           │ 0.2            │\n",
      "╘══════════════╧════════════════╧════════════════╧════════════════╧════════════════╛\n"
     ]
    }
   ],
   "source": [
    "print(student_model.get_cpds('grade'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Independencies in Bayesian Networks \n",
    "Independencies implied the by the structure of our bayesian network can be categorized in 2 types:\n",
    "> 1. **Local Independencies:** Any variable in the network that is independent of its non-descendents given its parents. Mathematically it can be written as:<br>\n",
    "<br>\n",
    "$$X \\perp NonDesc(X)|Pa(X)$$\n",
    "where $NonDesc(X)$ is the set of variables which are not descendents of $X$ and $Pa(X)$ is the set of variables whcih are parents of $X$. \n",
    "2. **Global Independencies:** For discussing global independencies in bayesian networks we need to look at the various network structures possible. Starting with the case of 2 nodes, there are only 2 possible ways for it to be connected:\n",
    "\n",
    "<img src=\"images/two_nodes.png\">\n",
    "\n",
    "In the above two caes it is obvious that change in either node will effect the other. For the first case we can take the example of $difficulty \\rightarrow grade$. If we increase the difficulty of the course the probability of getting a higher grade decreases. For the second case we can take the example of $ SAT \\leftarrow Intel $. Now if we increase the probability of getting a good score in SAT that would imply that the student is intelligent, hence increasing the probability of $ i_1 $. Therefore in both the cases shown above any change in the variables leads to change in the other variable.\n",
    "\n",
    "Now, there are four possible ways of connection between 3 nodes:\n",
    "\n",
    "<img src=\"images/three_nodes.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now in the above cases we will see the flow of influence from $ A $ to $ C $ under various cases.\n",
    "\n",
    "1. **Causal**: In the general case when we make any changes in the variable $ A $, it will have an effect on variable $ B $ (as we discussed above) and this change in $ B $ will change the values in $ C $. One other possible case can be when $ B $ is observed i.e. we know the value of $ B $. So, in this case any change in $ A $ won't affect $ B $ since we already know the value. And hence there won't be any change in $ C $ as it depends only on $ B $. Mathematically we can say that: \n",
    "$$ (A \\perp C | B) $$\n",
    "2. **Evidential**: Similarly in this case also observing $ B $ renders $ C $ independent of $ A $. Otherwise when $ B $ is not observed the influence flows from $ A $ to $ C $. Hence:\n",
    "$$ (A \\perp C | B) $$\n",
    "3. **Common Cause**: The influence flows from $ A $ to $ C $ when $ B $ is not observed. But when $ B $ is observed and change in $ A $ doesn't affect $ C $ since it's only dependent on $ B $. Hence here also:\n",
    "$$ ( A \\perp C | B) $$\n",
    "4. **Common Evidence**: This case is a bit different from the others. When $ B $ is not observed any change in $ A $ reflects some change in $ B $ but not in $ C $. Let's take the example of $ D \\rightarrow G \\leftarrow I $. In this case if we increase the difficulty of the course the probability of getting a higher grade reduces but this has no effect on the intelligence of the student. But when $ B $ is observed let's say that the student got a good grade. Now if we increase the difficulty of the course this will increase the probability of the student to be intelligent since we already know that he got a good grade. Hence in this case \n",
    "$$ (A \\perp C) $$ \n",
    "and \n",
    "$$ ( A \\not\\perp C | B) $$\n",
    "This structure is also commonly known as **V structure**. \n",
    "\n",
    "We can see this in greater detail by utilizing pgmpy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Find Local Independencies\n",
    "We can look at the independencies for specific nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(difficulty _|_ letter, grade, intelligence, sat)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_model.local_independencies('difficulty')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(grade _|_ letter, sat | difficulty, intelligence)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_model.local_independencies('grade')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(difficulty _|_ letter, grade, intelligence, sat)\n",
       "(intelligence _|_ letter, difficulty, grade, sat)\n",
       "(sat _|_ letter, difficulty, grade | intelligence)\n",
       "(grade _|_ letter, sat | difficulty, intelligence)\n",
       "(letter _|_ difficulty, intelligence, sat | grade)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_model.local_independencies(['difficulty', 'intelligence', 'sat', 'grade', 'letter'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(difficulty _|_ intelligence, sat)\n",
       "(difficulty _|_ letter | grade)\n",
       "(difficulty _|_ sat | intelligence)\n",
       "(difficulty _|_ intelligence | sat)\n",
       "(difficulty _|_ sat | letter, intelligence)\n",
       "(difficulty _|_ letter, sat | grade, intelligence)\n",
       "(difficulty _|_ letter | grade, sat)\n",
       "(difficulty _|_ sat | letter, grade, intelligence)\n",
       "(difficulty _|_ letter | grade, intelligence, sat)\n",
       "(grade _|_ sat | intelligence)\n",
       "(grade _|_ sat | letter, intelligence)\n",
       "(grade _|_ sat | difficulty, intelligence)\n",
       "(grade _|_ sat | letter, difficulty, intelligence)\n",
       "(intelligence _|_ difficulty)\n",
       "(intelligence _|_ letter | grade)\n",
       "(intelligence _|_ difficulty | sat)\n",
       "(intelligence _|_ letter | difficulty, grade)\n",
       "(intelligence _|_ letter | grade, sat)\n",
       "(intelligence _|_ letter | difficulty, grade, sat)\n",
       "(letter _|_ difficulty, intelligence, sat | grade)\n",
       "(letter _|_ sat | intelligence)\n",
       "(letter _|_ intelligence, sat | difficulty, grade)\n",
       "(letter _|_ sat | difficulty, intelligence)\n",
       "(letter _|_ difficulty, sat | grade, intelligence)\n",
       "(letter _|_ difficulty, intelligence | grade, sat)\n",
       "(letter _|_ sat | difficulty, grade, intelligence)\n",
       "(letter _|_ intelligence | difficulty, grade, sat)\n",
       "(letter _|_ difficulty | grade, intelligence, sat)\n",
       "(sat _|_ difficulty)\n",
       "(sat _|_ letter | grade)\n",
       "(sat _|_ letter, difficulty, grade | intelligence)\n",
       "(sat _|_ difficulty, grade | letter, intelligence)\n",
       "(sat _|_ letter | difficulty, grade)\n",
       "(sat _|_ letter, grade | difficulty, intelligence)\n",
       "(sat _|_ letter, difficulty | grade, intelligence)\n",
       "(sat _|_ grade | letter, difficulty, intelligence)\n",
       "(sat _|_ difficulty | letter, grade, intelligence)\n",
       "(sat _|_ letter | difficulty, grade, intelligence)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_model.get_independencies()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Find Active Trail Nodes\n",
    "We can also look for **active trail nodes**. We can think of active trail nodes as path's of influence; what can give you information about something else?   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'difficulty': {'difficulty', 'grade', 'letter'}}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_model.active_trail_nodes('difficulty')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'grade': {'difficulty', 'grade', 'intelligence', 'letter', 'sat'}}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_model.active_trail_nodes('grade')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that for `grade` we had everything be fully returned. This is because everything provides information about grade, meaning grade is dependent upon all other random variables. \n",
    "\n",
    "We can also see how the active trails to difficulty change when we observed `grade`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'difficulty': {'difficulty', 'grade', 'letter'}}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_model.active_trail_nodes('difficulty')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'difficulty': {'difficulty', 'intelligence', 'sat'}}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_model.active_trail_nodes('difficulty', observed='grade')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---\n",
    "\n",
    "## 3. Inference in Bayesian Models\n",
    "Until now we discussed just about representing Bayesian Networks. Now let's see how we can do inference in a Bayesian Model and use it to predict values over new data points for machine learning tasks. In this section we will consider that we already have our model (structure and parameters).\n",
    "\n",
    "In inference we try to answer probability queries over the network given some other variables. So, we might want to know the probable grade of an intelligent student in a difficult class given that he scored good in SAT. So for computing these values from a Joint Distribution we will have to reduce over the given variables that is:\n",
    "#### $$ I = 1, D = 1, S = 1 $$ \n",
    "and then marginalize over the other variables that is \n",
    "#### $$ L $$ \n",
    "to get \n",
    "#### $$ P(G | I=1, D=1, S=1) $$\n",
    "But carrying on marginalize and reduce operations on the complete Joint Distribution is computationaly expensive since we need to iterate over the whole table for each operation and the table is exponential in size to the number of variables. But in Graphical Models we exploit the independencies to break these operations in smaller parts making it much faster.\n",
    "\n",
    "One of the very basic methods of inference in Graphical Models is **Variable Elimination**.\n",
    "\n",
    "### 3.1 Variable Elimination\n",
    "We know that:\n",
    "\n",
    "#### $$ P(D, I, G, L, S) = P(L|G) * P(S|I) * P(G|D, I) * P(D) * P(I) $$\n",
    "\n",
    "Now let's say we just want to compute the probability of G. For that we will need to marginalize over all the other variables.\n",
    "\n",
    "#### $$ P(G) = \\sum_{D, I, L, S} P(D, I, G, L, S) $$ \n",
    "##### $$ P(G) = \\sum_{D, I, L, S} P(L|G) * P(S|I) * P(G|D, I) * P(D) * P(I) $$\n",
    "#### $$ P(G) = \\sum_D \\sum_I \\sum_L \\sum_S P(L|G) * P(S|I) * P(G|D, I) * P(D) * P(I) $$\n",
    "\n",
    "Now since not all the conditional distributions depend on all the variables we can push the summations inside:\n",
    "\n",
    "#### $$ P(G) = \\sum_D P(D) \\sum_I P(G|D, I) * P(I) \\sum_S P(S|I) \\sum_L P(L|G) $$\n",
    "\n",
    "So, by pushing the summations inside we have saved a lot of computation because we have to now iterate over much smaller tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═════════╤══════════════╕\n",
      "│ grade   │   phi(grade) │\n",
      "╞═════════╪══════════════╡\n",
      "│ grade_0 │       0.3620 │\n",
      "├─────────┼──────────────┤\n",
      "│ grade_1 │       0.2884 │\n",
      "├─────────┼──────────────┤\n",
      "│ grade_2 │       0.3496 │\n",
      "╘═════════╧══════════════╛\n"
     ]
    }
   ],
   "source": [
    "from pgmpy.inference import VariableElimination\n",
    "infer = VariableElimination(student_model)\n",
    "print(infer.query(['grade']) ['grade'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "There can be cases in which we want to compute the conditional distribution let's say \n",
    "#### $$ P(G | D=0, I=1) $$\n",
    "\n",
    "In such cases we need to modify our equations a bit:\n",
    "\n",
    "#### $$ P(G | D=0, I=1) = \\sum_L \\sum_S P(L|G) * P(S| I=1) * P(G| D=0, I=1) * P(D=0) * P(I=1) $$\n",
    "#### $$ P(G | D=0, I=1) = P(D=0) * P(I=1) * P(G | D=0, I=1) * \\sum_L P(L | G) * \\sum_S P(S | I=1) $$\n",
    "\n",
    "In pgmpy we will just need to pass an extra argument in the case of conditional distributions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═════════╤══════════════╕\n",
      "│ grade   │   phi(grade) │\n",
      "╞═════════╪══════════════╡\n",
      "│ grade_0 │       0.9000 │\n",
      "├─────────┼──────────────┤\n",
      "│ grade_1 │       0.0800 │\n",
      "├─────────┼──────────────┤\n",
      "│ grade_2 │       0.0200 │\n",
      "╘═════════╧══════════════╛\n"
     ]
    }
   ],
   "source": [
    "print(infer.query(['grade'], \n",
    "                  evidence={'difficulty': 0, \n",
    "                            'intelligence': 1}) ['grade'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predicting values from new data points** <br>\n",
    "\n",
    "Predicting values from new data points is quite similar to computing the conditional probabilities. We need to query for the variable that we need to predict given all the other features. The only difference is that rather than getting the probabilitiy distribution we are interested in getting the most probable state of the variable.\n",
    "\n",
    "In pgmpy this is known as MAP query. Here's an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'grade': 2}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infer.map_query(['grade'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'grade': 0}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infer.map_query(['grade'], \n",
    "                evidence={'difficulty': 0, \n",
    "                          'intelligence': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'grade': 0}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infer.map_query(['grade'], \n",
    "                evidence={'difficulty': 0, \n",
    "                          'intelligence': 1, \n",
    "                          'letter': 1, \n",
    "                          'sat': 1})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
