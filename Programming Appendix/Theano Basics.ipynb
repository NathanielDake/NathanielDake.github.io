{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Theano Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Theano Tensor \n",
    "import theano.tensor as T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create a scalar, vector, and matrix as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = T.scalar('c')\n",
    "v = T.vector('v')\n",
    "A = T.matrix('A')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also have Tensors, which work with dimensionality 3 and up. This is commonly used when dealing with images that have _not_ been flattened. For instance, if we had a 28x28 image, and we wanted to store the images as squares and we had $N$ images, we would have an $Nx28x28$ (3 dimensional) tensor.\n",
    "\n",
    "Notice that the variables we have created so far _do not have values_, they are just symbols. This means we can even do algebra on them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dot production\n",
    "w = A.dot(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we actually set values to these variables? This is where _theano functions_ come into play. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import theano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "matrix_times_vector = theano.function(inputs=[A,v], outputs=w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can import numpy so we can create real arrays and call the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([17., 39.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_val = np.array([[1,2], [3,4]])\n",
    "v_val = np.array([5,6])\n",
    "\n",
    "w_val = matrix_times_vector(A_val, v_val)\n",
    "w_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the greatest benefits of theano is that it links all of these variables up into a graph. We can use that structure to calculate gradients for you, using the chain rule! In theano, regular variables are _not_ updateable. In order for a variable to be updateable it must be a _shared_ variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = theano.shared(20.0, 'x')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now create a simple cost function that we can solve ourselves, and that we know has a global minimum. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cost = x*x + x + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can tell theano how to update $x$ by giving it an update expression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_update = x - 0.3*T.grad(cost, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is nice about theano is that it calculates gradients automatically. The `grad` function takes in two parameters. The first is the function you want to take the gradient of, and the second is the variable you want the gradient with respect to. \n",
    "\n",
    "We can now create a theano train function. It will be like the previous function we created, except we are going to add a new argument which is updates. The updates argument takes in a list of tuples, and each tuple has two things in it: \n",
    "1. The shared variable to update.\n",
    "2. The update expression to use. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = theano.function(inputs=[], outputs=cost, updates=[(x, x_update)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have created a function to train, but we haven't actually called it yet. Notice that $x$ is not an input, it is the thing that we update. In later examples the inputs will be the data and labels. So, the inputs param takes in data and labels, and the updates param takes in your model parameters with their updates.\n",
    "\n",
    "Now we can write a loop to call the training function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "421.0\n",
      "67.99000000000001\n",
      "11.508400000000002\n",
      "2.4713440000000007\n",
      "1.0254150400000002\n",
      "0.7940664064\n",
      "0.7570506250240001\n",
      "0.75112810000384\n",
      "0.7501804960006143\n",
      "0.7500288793600982\n",
      "0.7500046206976159\n",
      "0.7500007393116186\n",
      "0.750000118289859\n",
      "0.7500000189263775\n",
      "0.7500000030282203\n",
      "0.7500000004845152\n",
      "0.7500000000775223\n",
      "0.7500000000124035\n",
      "0.7500000000019845\n",
      "0.7500000000003176\n",
      "0.7500000000000506\n",
      "0.7500000000000082\n",
      "0.7500000000000013\n",
      "0.7500000000000001\n",
      "0.7500000000000001\n"
     ]
    }
   ],
   "source": [
    "for i in range(25):\n",
    "  cost_val = train()\n",
    "  print(cost_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We converge very quickly to the expected cost. We can print the optimal value of $x$ using the `get_value` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(-0.5)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.get_value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
