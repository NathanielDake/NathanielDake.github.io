{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. From Markov Models to Hidden Markov Models\n",
    "We are now going to extend the basic idea of markov models to hidden markov models. We have talked about latent variables before, and they will be a very important concept as we move forward. They show up in **K-means clustering**, **Gaussian Mixture Models**, **principle components analysis**, and many other areas. With hidden markov models, it even shows up in the name, so you know that hidden (latent) variables are central to this model. \n",
    "\n",
    "The basic idea behind a latent variable is that there is something going on beyond what we can observe/measure. What we observe is generally stochastic/random, since if it were deterministic we could predict it without doing any machine learning at all. The assumption that we make when we assume there are latent or hidden variables is that there is some cause behind the scenes that is leading to the observations that we see. In hidden markov models, the hidden cause itself is stochastic-it is a random process, the markov chain. \n",
    "\n",
    "An example of this can be seen in genetics. As a human, we are just a physical manifestation of some biological code. Now that the code is readable, it is not hidden in the sense that we can't measure it, but there was a time when we couldn't. At that point, people would use HMM's to determine how genes map to actual physical attributes. \n",
    "\n",
    "Another example is speech to text. A computer isn't able to read the words you are attempting to say, but it can use an internal language model-i.e. a model of likely sequences of hidden states, to try and match those to the sounds that it hears. So, in this case what is observed are the sound signal, and the latent variables are just the sentence or phrase that you are saying. \n",
    "\n",
    "## 1.1 Markov $\\rightarrow$ Hidden Markov\n",
    "So, how do we go from markov models to hidden markov models? The simplest way to explain this is via an example. Suppose you are at a carnival and a magician has two biased coins that he is hiding behind his back. He will choose to flip one of the coins at random, and all you get to see is the result of the coin toss (H/T). So, what are the **hidden states** and what are the **observed variables**? \n",
    "\n",
    "* Since we can see the results of the coin toss, that means heads and tails are our *observed variables*. We can think of this as a vocabulary or space of possible observed values. \n",
    "* The **hidden states**, of course, are which coin the magician chose to flip. We can't see them, so they are hidden. This is called a stochastic or random process, since it is a sequence of random variables. \n",
    "\n",
    "## 1.2 Define an HMM\n",
    "How do we actually go about defining an HMM? Well, an HMM has 3 parts:\n",
    "> **$\\pi$, A, B**\n",
    "\n",
    "(Note that this is opposed to the regular markov model which just has $\\pi$ and $A$). $\\pi$ is the **initial state distribution**, or the probability of being in a state when the sequence begins. In our coin example, say the magician really likes coin 1, so the probability that he starts with coin 1 is 0.9.\n",
    "\n",
    "#### $$\\pi_i = 0.9$$\n",
    "\n",
    "$A$ is the state transition matrix, which tells us the probability of going from one state to another. \n",
    "\n",
    "#### $$A(i,j) = probability \\; of \\; going \\; to \\; state \\; j \\; from \\; state \\; i$$\n",
    "\n",
    "\n",
    "In hidden markov models, the states themselves are hidden, so $A$ corresponds from transitioning from one hidden state to another hidden state. In the coin example, suppose the magician is very figity, and the probability of transitioning from coin 1 to coin 2 is 0.9, and the probability of transitioning from 2 to 1 is 0.9. Then, the probability of staying with the same coin for either coin is 0.1.\n",
    "\n",
    "$$A = \\begin{bmatrix}\n",
    "    A_{11} & A_{12}\\\\\n",
    "    A_{21} & A_{22} \n",
    "\\end{bmatrix}\n",
    "= \\begin{bmatrix}\n",
    "    0.1 & 0.9\\\\\n",
    "    0.9 & 0.1 \n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "The new variable here of course is $B$. This is the probability of observing some symbol given what state you are in. Note this also a matrix because it has two inputs. What state you are in, which is $j$, and what you observe, which is $k$. \n",
    "\n",
    "#### $$B(j,k) = probability \\; of \\;observing \\;symbol\\;k\\;while\\;you\\;are\\;in\\;state\\;j$$\n",
    "\n",
    "## 1.3 Indepence Assumptions\n",
    "In the HMM we are making more independence assumptions than just the markov assumption. Remember, the markov assumption is that the current state only depends on the previous state, but is independent of any state before the previous state. Now that we have both observed and hidden variables in our model, we have another independence assumption: \n",
    "\n",
    "> \"What we observe is only dependent on the current state\"\n",
    "\n",
    "So, the observation at time $t$, depends only on the state at time $t$, but not at any other time, state, or observation. \n",
    "\n",
    "## 1.4 What can we do with an HMM? \n",
    "So, what are we able to do with an HMM once we have one? Well, it will be similar to what we had discussed with regular markov models, with some additions. With markov models there were two main things we could do:\n",
    "> 1. **Get the probability of a sequence**. This was just the multiplication of each state transition probability, and the probability of the initial state.  \n",
    "2. **Train the model.** For this we just used maximum likelihood. That was just using frequency counts. \n",
    "\n",
    "With HMM's, we still have these two tasks, but both of these will be harder due to a more complex model. Training will most definitely be harder, because it not only requires the expectation maximization algorithm, but we will run into the limits of the numerical accuracy of the computer (limited accuracy of float). \n",
    "\n",
    "There is also one more task we will go over: *finding the most likely sequence of hidden states*. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<br>\n",
    "# 2. HMM's are Doubly Embedded \n",
    "Let's now discuss how HMM's are doubly embedded stochastic processes. Why do we say that they are doubly embedded? Well, think of the inner most layer. This is already a markov model, which is a specific type of stochastic process. With regular markov models, that is all we need-you know the state, end of story. With hidden markov models, once we hit a state there is yet another random sample that must be drawn. Think about our magician example: once the magician chooses the coin (1 or 2) he still has to flip the coin. So, we pick a state and then we have another random variable whose value has to be observed. \n",
    "\n",
    "We can think of this as two layers:\n",
    "\n",
    "> * On the inner most layer, the state is chosen (choosing of coin). \n",
    "* On the outer layer, once the state is chosen a random variable is generated using the observation distribution for that state. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<br>\n",
    "# 3. How can we chose the number of hidden states?\n",
    "The number of hidden states is a **hyperparameter**. In order to chose the number of hidden states, in general we would use *cross validation*. Well, if you think about, say we have $N$ training samples, and we then create a model with $N$ parameters. We could easily train this model to achieve 100% classication accuracy, however, this does not say anything about how the model will generalize to *unseen data*. Our goal will always be to fit to the trend, and not to the noise. If we can capture the real underlying trend, we should be able to make good predictions on new data. So, we will chose the number of hidden states that gives us the highest validation accuracy. We can use K-folds cross-validation. \n",
    "\n",
    "Generally that is all we would need to do when talking about hyperparameters. However, HMM's are a bit different. A lot of the time, the number of states in an HMM can reflect a real physical situation, or what we know about the situation we are trying to model-aka *priori knowledge*. For instance, in the magician example, we know the magician only has two coins, so we would use two states. When we are doing speech to text, we know the number of words in our vocabulary. In addition, we can separately train the hidden state transitions on pure text to give us a good initialization on the transition probabilities. Another example is biology-a codon is sequence of 3 DNA or RNA nucleotides, and these are responsible for creating amino acids which are then turned into proteins. A simple HMM may then have 3 physical states. So, we can use our knowledge of the physical system to help us determine the number of hidden states.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. The Forward-Backward Algorithm\n",
    "The first question that we can ask of our HMM is the simplest one: \n",
    "\n",
    ">\"What is the probability of a sequence?\"\n",
    "\n",
    "Suppose we have $M$ hidden states, and our sequence of observations is of length $T$. The idea is that we want to *marginalize* the joint probability over all possible values of the hidden states. \n",
    "\n",
    "So, we start with:\n",
    "\n",
    "#### $$p(x,z)$$\n",
    "\n",
    "Where both $x$ and $z$ are vectors:\n",
    "\n",
    "#### $$x = \\big[x(1), x(2), ..., x(T)\\big]$$\n",
    "#### $$z = \\big[z(1), z(2), ..., z(T)\\big]$$\n",
    "\n",
    "However, we want to be able to marginalize out $z$ and find:\n",
    "\n",
    "#### $$p\\big(x(1), x(2),...,x(T)\\big)$$\n",
    "\n",
    "The final equation we end up with is:\n",
    "\n",
    "$$p\\big(x(1), x(2),...,x(T)\\big) = \\sum_{z(1)=1..M,...,z(T)=1..M}\\pi\\big(z(1)\\big)p\\big(x(1)|z(1)\\big)\\prod_{t=2}^Tp\\big(z(t)|z(t-1)\\big)p\\big(x(t)|z(t)\\big)$$\n",
    "\n",
    "<br>\n",
    "Which when we break it down we see that we have **the probability of the initial state**: \n",
    "#### $$\\pi\\big(z(1)\\big)p\\big(x(1)|z(1)\\big)$$\n",
    "\n",
    "We have **A, the probability of going to state j from state i**:\n",
    "#### $$p\\big(z(t)|z(t-1)\\big)$$\n",
    "#### $$A(i,j) = p\\big(z(t)=j|z(t-1)=i\\big)$$\n",
    "\n",
    "And we have **B, the probability of seeing symbol k from state j**:\n",
    "#### $$p\\big(x(t)|z(t)\\big)$$\n",
    "#### $$B(j,k) = p\\big(x(t)=k|z(t)=j\\big)$$\n",
    "\n",
    "By performing our marginalization:\n",
    "\n",
    "#### $$\\sum_{z(1)=1..M,...,z(T)=1..M}$$\n",
    "\n",
    "We are essentially saying: \n",
    "> For the hidden variable at state 1, we want to look at *each potential value* of z. So in the case of the magician, at state 1, we would perform the calculation if coin 1 was used, z(1) and then add that the calculation if coin two was used, z(2). We would then perform this again from state 2, and all the way up through state $T$. This process of marginalization is based on the product rule of probability. \n",
    "\n",
    "The question is, how long will this take to calculate?  Well, in the inner part we have a product which is $2T - 1$, which can be seen based on the first product:\n",
    "\n",
    "$$\\prod_{t=2}^Tp\\big(z(t)|z(t-1)\\big)p\\big(x(t)|z(t)\\big)$$\n",
    "\n",
    "Which is multipled by:\n",
    "\n",
    "$$\\pi\\big(z(1)\\big)p\\big(x(1)|z(1)\\big)$$\n",
    "\n",
    "Given us the second product. this occurs for a total of $T$ times, hence $2T$ products. We then subtract 1 from this based on where $T$ is initialized, leaving us with $2T -1$ products. How many times do we need to compute this product? This is equal to the number of possible state sequences, which is $M^T$. So in total that leaves us with $O(TM^T)$. This is exponential growth which is pretty bad, so we don't want to do this. A better way of doing this would be the forward backward algorithm. The main issue that is causing us so many problems is that we have a product inside of a sum. Normally, we can't simplify a product inside of a sum, but in this case we can factor the expression using the properties of probability to reduce the number of calculations we have to do. \n",
    "\n",
    "## 4.1 Forward-Backword Algorithm Process\n",
    "So, how does the forward backward algorithm actually work? We need to define a variable called $\\alpha$. This is the forward variable, and it represents the joint probability of seeing the sequence you have observed up until now and being in a specific state at that time. \n",
    "\n",
    "#### $$\\alpha(t,i) = p\\big(x(1),...,x(t), z(t)=i\\big)$$\n",
    "\n",
    "We can see that there are two index's to $\\alpha$: time and $i$, which index's the state.\n",
    "\n",
    "#### 4.1.1 Step 1\n",
    "So, our first step is to calculate the initial value of $\\alpha$ (t = 1):\n",
    "\n",
    "#### $$\\alpha(t,i) = \\pi_iB\\big(i, x(t)\\big)$$\n",
    "#### $$\\alpha(1,i) = \\pi_iB\\big(i, x(1)\\big)$$\n",
    "\n",
    "#### 4.1.2 Step 2\n",
    "The second step is called the **induction step**. This will be done for every state and every time up until $T$. \n",
    "\n",
    "#### $$\\alpha(t+1, j) = \\sum_{i=1}^M \\alpha(t,i) A(i,j)B(j, x(t+1))$$\n",
    "\n",
    "#### 4.1.3 Step 3\n",
    "The final step is the termination step, where we marginalize over the hidden states at time $T$. \n",
    "\n",
    "#### $$p(x) = \\sum_{i=1}^M\\alpha(T,i) = \\sum_{i=1}^M p\\big(x(1),...,x(T),z(t)=i\\big)$$\n",
    "\n",
    "Notice that we already have our answer. We already know the probability of the sequence after only having done the forward step of the forward-backward algorithm. We can also show that the time complexity of this algorithm is $O(M^2T)$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
