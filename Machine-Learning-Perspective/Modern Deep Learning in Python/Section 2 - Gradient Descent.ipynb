{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Gradient Descent: Full vs. Batch vs. Stochastic\n",
    "Let's take a moment to talk about the different ways that we can perform gradient descent, and their particular advantages and disadvantages. The three basic types we will go over are:\n",
    "1. **Full**\n",
    "2. **Batch**\n",
    "3. **Stochastic**\n",
    "\n",
    "## 1.1 Full Gradient Descent\n",
    "Up until, most of my notebooks have covered **full** gradient descent:\n",
    "\n",
    "#### $$J = \\sum_{n=1}^N t(n)logy(n)$$\n",
    "\n",
    "Why is that? Well it makes sense that we would want to maximize the likelihood over our entire training set! The main disadvantage of this however is that the calculation of the gradient is now **O(N)**, since it depends on each sample. This means that it will struggle to be effective when working with big data. \n",
    "\n",
    "## 1.2 Stochastic Gradient Descent\n",
    "On the other end of the spectrum we have **stochastic gradient descent**. This looks at one particular sample at a time, and the associated error. We are depending on the fact that all of the samples are **IID (independent and identically distributed)**. This means that in the long run your error will improve because all of your samples are coming from the same distribution. Now that we have reduced our calculation from $N$ operations to 1, that is a nice improvement, however, there is a disadvantage. Whereas the log likelihood always improves on every iteration of full gradient descent, sometimes the log likelihood can get worse with stochastic gradient descent. In fact, the cost function will behave pretty erratically over each iteration, but it will improve in the long run. \n",
    "\n",
    "## 1.3 Batch Gradient Descent\n",
    "Batch gradient descent can be thought of as the happy medium between these two. In this method we split our data up into batches. For instance, say we have 10,000 examples, we could split it up into 100 batches of size 100. Then we could compute our cost function based on each batch for each iteration. In this case the cost function can still get worse, but it will be much less erratic than if we had done pure stochastic gradient descent. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Full vs. Batch vs. Stochastic in Code\n",
    "We are now going to compare each form of gradient descent in code, particularly how they progress. We start with the standard imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from datetime import datetime\n",
    "\n",
    "from util import get_transformed_data, forward, error_rate, cost, gradW, gradb, y2indicator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using the transformed data (after PCA has been applied). We will also be using logistic regression instead of a full neural network, just to speed things up. So we will start by getting the transformed data, and only take the first 300 columns. We will also normalize X, get our training and test set, and create our indicator matrices. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in and transforming data...\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10f367240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X, Y, _, _ = get_transformed_data()\n",
    "X = X[:, :300]\n",
    "\n",
    "# normalize X first\n",
    "mu = X.mean(axis=0)\n",
    "std = X.std(axis=0)\n",
    "X = (X - mu) / std\n",
    "\n",
    "Xtrain = X[:-1000,]\n",
    "Ytrain = Y[:-1000]\n",
    "Xtest  = X[-1000:,]\n",
    "Ytest  = Y[-1000:]\n",
    "\n",
    "N, D = Xtrain.shape\n",
    "Ytrain_ind = y2indicator(Ytrain)\n",
    "Ytest_ind = y2indicator(Ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Full Gradient Descent\n",
    "Now we will perform full gradient descent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = np.random.randn(D, 10) / 28    # initialize weights and bias\n",
    "b = np.zeros(10)\n",
    "LL = []\n",
    "lr = 0.0001                        # set learning rate and regularization\n",
    "reg = 0.01\n",
    "t0 = datetime.now()\n",
    "for i in range(200):\n",
    "    p_y = forward(Xtrain, W, b)    # forward pass\n",
    "\n",
    "    W += lr*(gradW(Ytrain_ind, p_y, Xtrain) - reg*W  # weight and bias update using gradient\n",
    "    b += lr*(gradb(Ytrain_ind, p_y) - reg*b)\n",
    "\n",
    "\n",
    "    p_y_test = forward(Xtest, W, b)                  # forward pass on test set\n",
    "    ll = cost(p_y_test, Ytest_ind)\n",
    "    LL.append(ll)\n",
    "    if i % 20 == 0:\n",
    "        err = error_rate(p_y_test, Ytest)\n",
    "        print(\"Cost at iteration %d: %.6f\" % (i, ll))\n",
    "        print(\"Error rate:\", err)\n",
    "p_y = forward(Xtest, W, b)                                    # final prediction\n",
    "print(\"Final error rate:\", error_rate(p_y, Ytest))            # print accuracy\n",
    "print(\"Elapsted time for full GD:\", datetime.now() - t0)      # print current time "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
