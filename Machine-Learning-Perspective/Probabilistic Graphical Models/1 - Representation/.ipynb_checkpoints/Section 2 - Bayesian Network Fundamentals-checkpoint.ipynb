{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Bayesian Networks - Semantics and Factorization \n",
    "\n",
    "We are about to dig further into the actual representation behind a bayesian network and how it is constructed from a set of factors. We will continue with our example from section 1.\n",
    "\n",
    "Recall, our example consisted of a student who is taking a class for a grade. In this example, we represented that following variables with their first letter:\n",
    "\n",
    "```\n",
    "Grade - G (A, B, C)\n",
    "Course Difficulty - D (1/0)\n",
    "Student Intelligence - I (1/0)\n",
    "Student SAT - S (1/0)\n",
    "Reference Letter - L (1/0)\n",
    "```\n",
    "\n",
    "And our joint distribution would be represented with: \n",
    "\n",
    "#### $$P(G, D, I, S, L)$$\n",
    "\n",
    "And now, we can just ask ourselves:\n",
    "\n",
    "> \"What does the grade of the student depend on?\"\n",
    "\n",
    "Well, it makes sense that the grade would depend on the intelligence of the student and the difficulty of the class. \n",
    "\n",
    "<img src=\"images/bn-1.png\" height=\"200\" width=\"200\">\n",
    "\n",
    "This is already a small bayesian network! We can then take the other random variable and introduce them into the mix. So for example, the SAT score of the  student doesn't seem to depend on the difficulty of the course or on the grade  that the student gets in the course. The only thing it's likely to depend on  in the context of this model is the intelligence of the student.\n",
    "\n",
    "<img src=\"images/bn-2.png\" height=\"300\" width=\"300\">\n",
    "\n",
    "And finally, caricaturing the way in which instructors write recommendation  letters- we're going to assume that the quality of the letter depends only on the student's grade.\n",
    "\n",
    "<img src=\"images/bn-3.png\" height=\"300\" width=\"300\">\n",
    "\n",
    "Now, the above figure is a model our the dependencies. Keep in mind that it is not set in stone (can change), but it is just a representation of how we believe the world works. \n",
    "\n",
    "The question that you may have is:\n",
    "\n",
    "> *How do we get this to represent a probability distribution?*\n",
    "\n",
    "Currently it is just a bunch of nodes stuck together with edges; how do we turn that into a clear probability distribution? Well, we are going to annotate each of the nodes in the network with a **conditional probability distribution**, or **CPD**. \n",
    "\n",
    "<img src=\"images/cpd-annotated.png\">\n",
    "\n",
    "Now, each of these is a CPD. So, we have 5 nodes and subsequently 5 CPD's. Now, if you look at some of these CPDs,  they're kind of degenerate, so for example, the difficulty CPD isn't  actually conditioned on anything. It's just an unconditional probability  distribution that tells us that courses are only 40% likely to be difficult and 60% likely to be easy. Intelligence in this case is also unconditioned.\n",
    "\n",
    "#### $$P(D)$$\n",
    "#### $$P(I)$$\n",
    "\n",
    "Now this gets more interesting when you look at the actual conditional  probability distributions. So, we can see the conditional probability grade distribution that we've already seen before for the probability of grade given intelligence, and difficulty, and we've  already discussed how each of these rows necessarily sums to one because the  probability distribution over the variable grade. And we have two other  CPD's here. In this case, the probability of SAT  given intelligence and the probability of letter given grade.  \n",
    "\n",
    "#### $$P(G \\; | \\; I, D)$$\n",
    "#### $$P(L \\; | \\; G)$$\n",
    "#### $$P(S \\; | \\; I)$$\n",
    "\n",
    "And that now is a **fully parameterized Bayesian network** and what we'll show next  is how this Bayesian network produces a joint probability distribution over these  five variables. So, here are the CPDs:\n",
    "\n",
    "<img src=\"images/cpd-prob.png\">\n",
    "\n",
    "And what we're going to define now is the **chain rule** for Bayesian networks. The chain rule basically takes these different CPDs and  multiplies them together:\n",
    "\n",
    "#### $$P(D, I, G, S, L) = P(D)*P(I)*P(G|I, D)*P(S|I)*P(L |G)$$\n",
    "\n",
    "Now, before we think of what that means, let us first note that this is actually a  factor product in exactly the same way that we just defined.  So here, we have five factors, they have overlapping scopes and what we  end up with is a factor product that gives us a big, big factor whose scope is  five variables. So what does that translate into when we  apply the chain rule for Bayesian networks in the context of the particular  example? Assume we are trying to compute the following:\n",
    "\n",
    "#### $$P(d^0, i^1, g^3, s^1, l^1)$$\n",
    "\n",
    "Well, based on our factors from the figure above, if we start at **Difficulty** and **Grade**, we end up with:\n",
    "\n",
    "#### $$0.6 * 0.3 * 0.2 * 0.8 *0.01$$\n",
    "\n",
    "So, what does that give us as a definition? \n",
    "\n",
    "> **Bayesian Network:** *A Bayesian Network is a directed **acyclic** graph (DAG) G whose nodes represent the random variables $X_1,...,X_n$*. For each node in the graph, $X_i$, we have a CPD $P(X_i|Par_G(X_i))$, which denotes the dependents of $X_i$ on its parents in the graph G.\n",
    "\n",
    "The **BN** represents a joint probability distribution via the chain rule for bayesian networks:\n",
    "\n",
    "#### $$P(X_1,...,X_n) = \\prod_i P(X_i|Par_G(X_i))$$\n",
    "\n",
    "### 1.1 How do we know it is a legal Probability Distribution?\n",
    "We need to show, first off, that it is great than or equal to 0. In our case this is rather trivial, since $P$ is a product of CPD's, and CPD's are nonnegative. \n",
    "\n",
    "We must then show that it sums to 1. \n",
    "\n",
    "#### $$\\sum P = 1$$\n",
    "\n",
    "To show that in the context of our previous example, we can sum up over all possible assignments:\n",
    "\n",
    "#### $$\\sum_{D, I, G, S, L}P(D, I, G, S, L) = \\sum_{D, I, G, S, L}P(D)*P(I)*P(G|I, D)*P(S|I)*P(L |G)$$\n",
    "\n",
    "Above, we broke this up via the chain rule, since that is how we defined our distribution. Now, the trick that we will use to solve this is to realize that each factor only involves a small subset of the variables. This allows us to push the summations in. We can start by pushing in the summation over L:\n",
    "\n",
    "#### $$= \\sum_{D, I, G, S}P(D)*P(I)*P(G|I, D)*P(S|I)* \\sum _L P(L |G)$$\n",
    "\n",
    "Keep in mind that $\\sum _L P(L |G) = 1$. This is because no matter what the value of $G$ is, the probability of $L$ is well defined and will sum to one (look at the factor in the figure above). Another way to think about this is that we are summing up over the row of the CPD $P(L|G)$, and that means that the sum must be 1. This means that the term can be replaced with one, leaving us with:\n",
    "\n",
    "#### $$= \\sum_{D, I, G, S}P(D)*P(I)*P(G|I, D)*P(S|I)$$\n",
    "\n",
    "Now, we can do exactly the same thing with $S$:\n",
    "\n",
    "#### $$= \\sum_{D, I, G}P(D)*P(I)*P(G|I, D)* \\sum_S P(S|I)$$\n",
    "\n",
    "This too is the sum over the row of a CPD, meaning it will evaluate to 1. We now have: \n",
    "\n",
    "#### $$= \\sum_{D, I, G}P(D)*P(I)*P(G|I, D)$$\n",
    "\n",
    "We can now do the same thing with G:\n",
    "\n",
    "#### $$= \\sum_{D, I}P(D)*P(I)* \\sum_G P(G|I, D)$$\n",
    "\n",
    "Which again, yields 1. We could do the same process for both $D$ and $I$, leaving us finally with just 1. \n",
    "\n",
    "### 1.2 Terminology \n",
    "We can now define more of the terminology that is going to accompany us further on.\n",
    "\n",
    "**P Factorizes of G**<br>\n",
    "* Let $G$ be a graph over $X_1,...,X_n$\n",
    "* Then, $P$ factorizes of $G$ if:\n",
    "#### $$P(X_1,...,X_n) = \\prod_i P(X_i|Par_G(X_i))$$\n",
    "\n",
    "In other words, a distribution $P$ factorizes over $G$ (we can represent it over the graph $G$), if we can encode it using the chain rule for bayesian networks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---\n",
    "\n",
    "<br>\n",
    "# 2. Reasoning Patterns\n",
    "Now that we have the bayesian network defined, we can look at some of the reasoning patterns utilized. \n",
    "\n",
    "### 2.1 Causal Reasoning\n",
    "If we go back to our student network example with the following CPD's:\n",
    "\n",
    "<img src=\"images/cpd-annotated.png\">\n",
    "\n",
    "We can now look at some of the probabilities that one would get if you took the bayesian network, produced the joint distribution using the chain rule for bayesian networks, and now computed the values for different marginal probabilities. For instance, we could ask the probability of getting a strong letter. \n",
    "\n",
    "<img src=\"images/bn-marg-1.png\">\n",
    "\n",
    "We won't get through the calculation (tedious), but the probability of getting a strong letter is ~ 0.5. However, we can do more interesting queries. We can, for instance, condition on one variable, and ask how that changes this probability. For example, say we condition on low intelligence and use red to denote the false value:\n",
    "\n",
    "<img src=\"images/bn-marg-2.png\">\n",
    "\n",
    "#### $$P(l^1|i^0) \\approx 0.39$$\n",
    "\n",
    "The probability of a strong letter is now 0.39. It is not surprising that the probability in this case goes down. This makes sense seeing as an intelligence goes down, the probability of getting a good grade goes down, and so does the probability of getting a strong letter. The is an example of **causal reasoning**, because intuitively the reasoning goes in a causal direction; from top to bottom. \n",
    "\n",
    "We can also make things more interesting. We can ask what happens if we make the difficulty of the course low.\n",
    "\n",
    "<img src=\"images/bn-marg-3.png\">\n",
    "\n",
    "#### $$P(l^1|i^0, d^0) \\approx 0.51$$\n",
    "\n",
    "### 2.2 Evidential Reasoning\n",
    "We can also perform **evidential reasoning**, which goes from the bottom to the top. \n",
    "\n",
    "<img src=\"images/bn-marg-4.png\">\n",
    "\n",
    "So, we can condition on the grade and ask what happens to the probability of the parents. Imagine that there is a student who takes the class and gets a C. Initially, the probability that the class was difficult was:\n",
    "\n",
    "#### $$P(d^1) = 0.4$$\n",
    "\n",
    "And the probability that the student was intelligent was:\n",
    "\n",
    "#### $$P(i^1) = 0.3$$\n",
    "\n",
    "But, now with this additional evidence, the probability that the student was intelligent goes down:\n",
    "\n",
    "#### $$P(i^1|g^3) \\approx 0.08$$\n",
    "\n",
    "And the probability that the class was difficult goes up:\n",
    "\n",
    "#### $$P(d^1 | g^3) \\approx 0.63$$\n",
    "\n",
    "### 2.3 Intercausal Reasoning\n",
    "Now, there is another type of reasoning that is not quite as standard: **intercausal reasoning**. This is reasoning that is effectively the flow of information between two causes of a single effect. \n",
    "\n",
    "Let's go back to our situation where the student received a grade of C, $g^3$. \n",
    "\n",
    "<img src=\"images/bn-marg-5.png\">\n",
    "\n",
    "But now, we find out that this class really is difficult. So, we are going to condition on $d^1$. And now notice that the probability that the student is intelligent has gone up (from 0.08 to 0.11). \n",
    "\n",
    "<img src=\"images/bn-marg-6.png\">\n",
    "\n",
    "Now, that is not a huge increase. We will see as we play with more bayesian networks that the changes in probability are somewhat subtle. \n",
    "\n",
    "In another case, assume that the student gets a B. So now we have that the probability of high intelligence stills goes down\n",
    "\n",
    "<img src=\"images/bn-marg-7.png\">\n",
    "\n",
    "But now if we determine that the class is hard, the probability goes up (even higher than the originally probability).\n",
    "\n",
    "<img src=\"images/bn-marg-8.png\">\n",
    "\n",
    "### 2.4 Intercausal Reasoning Explained\n",
    "Let's look drill into a particular example to determine how intercausal reasoning really works. Below, we can see the purest form of intercausal reasoning.\n",
    "\n",
    "<img src=\"images/intercausal-1.png\">\n",
    "\n",
    "We have two random variables $X_1$ and $X_2$. We are going to assume that they are distributed uniformly (each has a 50% probability of being 1 and 50% probability of being 0). And we have on effect, which is simply the deterministic **OR**, of those two parents, which we represent as $Y$. In general, when we have a deterministic variable we will denote it with the double lines. \n",
    "\n",
    "Now, what if we condition on the evidence $Y = 1$. Before we conditioned on this evidence, $X_1$ and $X_2$ were independent of each other. However, after the conditioning, one entry in our table is removed, and we have:\n",
    "\n",
    "<img src=\"images/intercausal-2.png\">\n",
    "\n",
    "Where $X_1$ and $X_2$ are now dependent on each other. Why is that the case? Well, currently in the above probability distribution, the probability that $X_1 = 1$ is:\n",
    "\n",
    "#### $$P(X_1 = 1) = \\frac{2}{3}$$\n",
    "\n",
    "And the same thing for $X_2 = 1$:\n",
    "\n",
    "#### $$P(X_2 = 1) = \\frac{2}{3}$$\n",
    "\n",
    "Now, if we condition on $X_1 = 1$, we will remove the second row:\n",
    "\n",
    "<img src=\"images/intercausal-3.png\">\n",
    "\n",
    "And all of a sudden the probability of $X_2 = 1$ is back to 50%:\n",
    "\n",
    "#### $$P(X_2 =1 \\;|\\; X_1 =1) = 0.5$$\n",
    "\n",
    "The reason for this is that if we know that $Y = 1$, there are two things that could have made that true. Either $X_1 = 1$ or $X_2 = 1$. If we find out that $X_1 = 1$, we have completely explained what happened. This means that we want to go back to the way it was before (50/50), since there is nothing to suggest that it should be any other way. This particular situation is known as **explaining away**, and it is when one cause explains away a reason that made us suspect a different cause. \n",
    "\n",
    "### 2.5 Student Aces SAT\n",
    "So, let's go back to our example and look at a reasoning pattern that involves even longer paths in the graph. Let's imagine that our student gets a C, but we have an additional piece of information that they also ace the SAT. \n",
    "\n",
    "<img src=\"images/student-ace.png\">\n",
    "\n",
    "When we just had the evidence regarding the grade, we had the probability of the student being intelligent was only 0.08. But now we have an additional piece of conflicting evidence, and the probability goes up to 0.58. \n",
    "\n",
    "What is going to happen to difficulty. Now, it is explaining away an action going in a different direction. If it is not the fact that the student is not smart, then why did they get a bad grade? The reason is more likely that the class is very difficult.\n",
    "\n",
    "<img src=\"images/student-ace-2.png\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
