{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Learning Bayesian Networks\n",
    "Previous notebooks showed how Bayesian networks economically encode a probability distribution over a set of variables, and how they can be used to predict variable states, or to generate new samples from the joint distribution. This section will be about obtaining a Bayesian network, given a set of sample data. Learning a Bayesian network can be split into two problems:\n",
    "\n",
    "**Parameter learning**: Given a set of data samples and a DAG that captures the dependencies between the variables, estimate the (conditional) probability distributions of the individual variables.\n",
    "\n",
    "**Structure learning**: Given a set of data samples, estimate a DAG that captures the dependencies between the variables.\n",
    "\n",
    "This notebook aims to illustrate how parameter learning and structure learning can be done with pgmpy. Currently, the library supports:\n",
    "\n",
    "* Parameter learning for discrete nodes:\n",
    "    * Maximum Likelihood Estimation\n",
    "    * Bayesian Estimation\n",
    "* Structure learning for discrete, fully observed networks:\n",
    "    * Score-based structure estimation (BIC/BDeu/K2 score; exhaustive search, hill climb/tabu search)\n",
    "    * Constraint-based structure estimation (PC)\n",
    "    * Hybrid structure estimation (MMHC)\n",
    "    \n",
    "## 1.1 Parameter Learning \n",
    "Suppose we have the following data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.DataFrame(data={'fruit': [\"banana\", \"apple\", \"banana\", \"apple\", \"banana\",\"apple\", \"banana\", \n",
    "                                    \"apple\", \"apple\", \"apple\", \"banana\", \"banana\", \"apple\", \"banana\",], \n",
    "                          'tasty': [\"yes\", \"no\", \"yes\", \"yes\", \"yes\", \"yes\", \"yes\", \n",
    "                                    \"yes\", \"yes\", \"yes\", \"yes\", \"no\", \"no\", \"no\"], \n",
    "                          'size': [\"large\", \"large\", \"large\", \"small\", \"large\", \"large\", \"large\",\n",
    "                                    \"small\", \"large\", \"large\", \"large\", \"large\", \"small\", \"small\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     fruit   size tasty\n",
      "0   banana  large   yes\n",
      "1    apple  large    no\n",
      "2   banana  large   yes\n",
      "3    apple  small   yes\n",
      "4   banana  large   yes\n",
      "5    apple  large   yes\n",
      "6   banana  large   yes\n",
      "7    apple  small   yes\n",
      "8    apple  large   yes\n",
      "9    apple  large   yes\n",
      "10  banana  large   yes\n",
      "11  banana  large    no\n",
      "12   apple  small    no\n",
      "13  banana  small    no\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know that the variable relate as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pgmpy.models import BayesianModel\n",
    "\n",
    "model = BayesianModel([('fruit', 'tasty'), ('size', 'tasty')])  # fruit -> tasty <- size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameter learning is the task to estimate the values of the conditional probability distributions (CPDs), for the variables fruit, size, and tasty.\n",
    "\n",
    "**State counts**<br>\n",
    "To make sense of the given data, we can start by counting how often each state of the variable occurs. If the variable is dependent on parents, the counts are done conditionally on the parents states, i.e. seperately for each parent configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "         fruit\n",
      "apple       7\n",
      "banana      7\n",
      "\n",
      " fruit apple       banana      \n",
      "size  large small  large small\n",
      "tasty                         \n",
      "no      1.0   1.0    1.0   1.0\n",
      "yes     3.0   2.0    5.0   0.0\n"
     ]
    }
   ],
   "source": [
    "from pgmpy.estimators import ParameterEstimator\n",
    "pe = ParameterEstimator(model, data)\n",
    "print(\"\\n\", pe.state_counts('fruit'))  # unconditional\n",
    "print(\"\\n\", pe.state_counts('tasty'))  # conditional on fruit and size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see, for example, that as many apples as bananas were observed and that 5 large bananas were tasty, while only 1 was not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Maximum Likelihood Estimation**<br>\n",
    "\n",
    "A natural estimate for the CPDs is to simply use the relative frequencies, with which the variable states have occured. We observed 7 `apples` among a total of 14 `fruits`, so we might guess that about 50% of `fruits` are `apples`.\n",
    "\n",
    "This approach is *Maximum Likelihood Estimation (MLE)*. According to MLE, we should fill the CPDs in such a way, that $P(\\text{data}|\\text{model})$ is maximal. This is achieved when using the relative frequencies. pgmpy supports MLE as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═══════════════╤═════╕\n",
      "│ fruit(apple)  │ 0.5 │\n",
      "├───────────────┼─────┤\n",
      "│ fruit(banana) │ 0.5 │\n",
      "╘═══════════════╧═════╛\n",
      "╒════════════╤══════════════╤════════════════════╤═════════════════════╤═══════════════╕\n",
      "│ fruit      │ fruit(apple) │ fruit(apple)       │ fruit(banana)       │ fruit(banana) │\n",
      "├────────────┼──────────────┼────────────────────┼─────────────────────┼───────────────┤\n",
      "│ size       │ size(large)  │ size(small)        │ size(large)         │ size(small)   │\n",
      "├────────────┼──────────────┼────────────────────┼─────────────────────┼───────────────┤\n",
      "│ tasty(no)  │ 0.25         │ 0.3333333333333333 │ 0.16666666666666666 │ 1.0           │\n",
      "├────────────┼──────────────┼────────────────────┼─────────────────────┼───────────────┤\n",
      "│ tasty(yes) │ 0.75         │ 0.6666666666666666 │ 0.8333333333333334  │ 0.0           │\n",
      "╘════════════╧══════════════╧════════════════════╧═════════════════════╧═══════════════╛\n"
     ]
    }
   ],
   "source": [
    "from pgmpy.estimators import MaximumLikelihoodEstimator\n",
    "mle = MaximumLikelihoodEstimator(model, data)\n",
    "print(mle.estimate_cpd('fruit'))  # unconditional\n",
    "print(mle.estimate_cpd('tasty'))  # conditional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`mle.estimate_cpd(variable)` computes the state counts and divides each cell by the (conditional) sample size. The `mle.get_parameters()`-method returns a list of CPDs for all variables of the model.\n",
    "\n",
    "The built-in `fit()`-method of `BayesianModel` provides more convenient access to parameter estimators:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calibrate all CPDs of `model` using MLE:\n",
    "model.fit(data, estimator=MaximumLikelihoodEstimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While very straightforward, the ML estimator has the problem of overfitting to the data. In above CPD, the probability of a large banana being tasty is estimated at 0.833, because 5 out of 6 observed large bananas were tasty. Fine. But note that the probability of a small banana being tasty is estimated at 0.0, because we observed only one small banana and it happened to be not tasty. But that should hardly make us certain that small bananas aren't tasty! We simply do not have enough observations to rely on the observed frequencies. If the observed data is not representative for the underlying distribution, ML estimations will be extremly far off.\n",
    "\n",
    "When estimating parameters for Bayesian networks, lack of data is a frequent problem. Even if the total sample size is very large, the fact that state counts are done conditionally for each parents configuration causes immense fragmentation. If a variable has 3 parents that can each take 10 states, then state counts will be done seperately for 10^3 = 1000 parents configurations. This makes MLE very fragile and unstable for learning Bayesian Network parameters. A way to mitigate MLE's overfitting is *Bayesian Parameter Estimation*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bayesian Parameter Estimation**:<br>\n",
    "The Bayesian Parameter Estimator starts with already existing prior CPDs, that express our beliefs about the variables before the data was observed. Those \"priors\" are then updated, using the state counts from the observed data.\n",
    "\n",
    "One can think of the priors as consisting in pseudo state counts, that are added to the actual counts before normalization. Unless one wants to encode specific beliefs about the distributions of the variables, one commonly chooses uniform priors, i.e. ones that deem all states equiprobable.\n",
    "\n",
    "A very simple prior is the so-called K2 prior, which simply adds 1 to the count of every single state. A somewhat more sensible choice of prior is BDeu (Bayesian Dirichlet equivalent uniform prior). For BDeu we need to specify an equivalent sample size N and then the pseudo-counts are the equivalent of having observed N uniform samples of each variable (and each parent configuration). In pgmpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒════════════╤═════════════════════╤════════════════════╤════════════════════╤═════════════════════╕\n",
      "│ fruit      │ fruit(apple)        │ fruit(apple)       │ fruit(banana)      │ fruit(banana)       │\n",
      "├────────────┼─────────────────────┼────────────────────┼────────────────────┼─────────────────────┤\n",
      "│ size       │ size(large)         │ size(small)        │ size(large)        │ size(small)         │\n",
      "├────────────┼─────────────────────┼────────────────────┼────────────────────┼─────────────────────┤\n",
      "│ tasty(no)  │ 0.34615384615384615 │ 0.4090909090909091 │ 0.2647058823529412 │ 0.6428571428571429  │\n",
      "├────────────┼─────────────────────┼────────────────────┼────────────────────┼─────────────────────┤\n",
      "│ tasty(yes) │ 0.6538461538461539  │ 0.5909090909090909 │ 0.7352941176470589 │ 0.35714285714285715 │\n",
      "╘════════════╧═════════════════════╧════════════════════╧════════════════════╧═════════════════════╛\n"
     ]
    }
   ],
   "source": [
    "from  pgmpy.estimators  import BayesianEstimator\n",
    "est = BayesianEstimator(model, data)\n",
    "\n",
    "print(est.estimate_cpd('tasty', prior_type='BDeu', equivalent_sample_size=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The estimated values in the CPDs are now more conservative. In particular, the estimate for a small banana being not tasty is now around 0.64 rather than 1.0. Setting equivalent_sample_size to 10 means that for each parent configuration, we add the equivalent of 10 uniform samples (here: +5 small bananas that are tasty and +5 that aren't).\n",
    "\n",
    "For a quick comparison, recall that the MLE parameters were as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒════════════╤══════════════╤════════════════════╤═════════════════════╤═══════════════╕\n",
      "│ fruit      │ fruit(apple) │ fruit(apple)       │ fruit(banana)       │ fruit(banana) │\n",
      "├────────────┼──────────────┼────────────────────┼─────────────────────┼───────────────┤\n",
      "│ size       │ size(large)  │ size(small)        │ size(large)         │ size(small)   │\n",
      "├────────────┼──────────────┼────────────────────┼─────────────────────┼───────────────┤\n",
      "│ tasty(no)  │ 0.25         │ 0.3333333333333333 │ 0.16666666666666666 │ 1.0           │\n",
      "├────────────┼──────────────┼────────────────────┼─────────────────────┼───────────────┤\n",
      "│ tasty(yes) │ 0.75         │ 0.6666666666666666 │ 0.8333333333333334  │ 0.0           │\n",
      "╘════════════╧══════════════╧════════════════════╧═════════════════════╧═══════════════╛\n"
     ]
    }
   ],
   "source": [
    "print(mle.estimate_cpd('tasty'))  # conditional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "And, if we were to keep increasing the `equivalent_sample_size`, we can see that our probabilities begin to approach 50/50. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒════════════╤═════════════════════╤═════════════════════╤═════════════════════╤════════════════════╕\n",
      "│ fruit      │ fruit(apple)        │ fruit(apple)        │ fruit(banana)       │ fruit(banana)      │\n",
      "├────────────┼─────────────────────┼─────────────────────┼─────────────────────┼────────────────────┤\n",
      "│ size       │ size(large)         │ size(small)         │ size(large)         │ size(small)        │\n",
      "├────────────┼─────────────────────┼─────────────────────┼─────────────────────┼────────────────────┤\n",
      "│ tasty(no)  │ 0.46551724137931033 │ 0.48214285714285715 │ 0.43548387096774194 │ 0.5192307692307693 │\n",
      "├────────────┼─────────────────────┼─────────────────────┼─────────────────────┼────────────────────┤\n",
      "│ tasty(yes) │ 0.5344827586206896  │ 0.5178571428571429  │ 0.5645161290322581  │ 0.4807692307692308 │\n",
      "╘════════════╧═════════════════════╧═════════════════════╧═════════════════════╧════════════════════╛\n",
      "╒════════════╤═════════════════════╤════════════════════╤═══════════════╤═════════════════════╕\n",
      "│ fruit      │ fruit(apple)        │ fruit(apple)       │ fruit(banana) │ fruit(banana)       │\n",
      "├────────────┼─────────────────────┼────────────────────┼───────────────┼─────────────────────┤\n",
      "│ size       │ size(large)         │ size(small)        │ size(large)   │ size(small)         │\n",
      "├────────────┼─────────────────────┼────────────────────┼───────────────┼─────────────────────┤\n",
      "│ tasty(no)  │ 0.49606299212598426 │ 0.4980237154150198 │ 0.4921875     │ 0.50199203187251    │\n",
      "├────────────┼─────────────────────┼────────────────────┼───────────────┼─────────────────────┤\n",
      "│ tasty(yes) │ 0.5039370078740157  │ 0.5019762845849802 │ 0.5078125     │ 0.49800796812749004 │\n",
      "╘════════════╧═════════════════════╧════════════════════╧═══════════════╧═════════════════════╛\n"
     ]
    }
   ],
   "source": [
    "print(est.estimate_cpd('tasty', prior_type='BDeu', equivalent_sample_size=100))\n",
    "print(est.estimate_cpd('tasty', prior_type='BDeu', equivalent_sample_size=1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`BayesianEstimator`, too, can be used via the `fit()`-method. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒══════╤══════════╕\n",
      "│ A(0) │ 0.499401 │\n",
      "├──────┼──────────┤\n",
      "│ A(1) │ 0.500599 │\n",
      "╘══════╧══════════╛\n",
      "╒══════╤══════╤══════╕\n",
      "│ A    │ A(0) │ A(1) │\n",
      "├──────┼──────┼──────┤\n",
      "│ B(0) │ 0.5  │ 0.5  │\n",
      "├──────┼──────┼──────┤\n",
      "│ B(1) │ 0.5  │ 0.5  │\n",
      "╘══════╧══════╧══════╛\n",
      "╒══════╤════════════════════╤════════════════════╤════════════════════╤════════════════════╕\n",
      "│ A    │ A(0)               │ A(0)               │ A(1)               │ A(1)               │\n",
      "├──────┼────────────────────┼────────────────────┼────────────────────┼────────────────────┤\n",
      "│ D    │ D(0)               │ D(1)               │ D(0)               │ D(1)               │\n",
      "├──────┼────────────────────┼────────────────────┼────────────────────┼────────────────────┤\n",
      "│ C(0) │ 0.5170641846034516 │ 0.5086758934104524 │ 0.4921951219512195 │ 0.5118439861139473 │\n",
      "├──────┼────────────────────┼────────────────────┼────────────────────┼────────────────────┤\n",
      "│ C(1) │ 0.4829358153965484 │ 0.4913241065895476 │ 0.5078048780487805 │ 0.4881560138860527 │\n",
      "╘══════╧════════════════════╧════════════════════╧════════════════════╧════════════════════╛\n",
      "╒══════╤══════╤══════╕\n",
      "│ B    │ B(0) │ B(1) │\n",
      "├──────┼──────┼──────┤\n",
      "│ D(0) │ 0.5  │ 0.5  │\n",
      "├──────┼──────┼──────┤\n",
      "│ D(1) │ 0.5  │ 0.5  │\n",
      "╘══════╧══════╧══════╛\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pgmpy.models import BayesianModel\n",
    "from pgmpy.estimators import BayesianEstimator\n",
    "\n",
    "# generate data\n",
    "data = pd.DataFrame(np.random.randint(low=0, high=2, size=(5000, 4)), columns=['A', 'B', 'C', 'D'])\n",
    "model = BayesianModel([('A', 'B'), ('A', 'C'), ('D', 'C'), ('B', 'D')])\n",
    "\n",
    "model.fit(data, estimator=BayesianEstimator, prior_type=\"BDeu\") # default equivalent_sample_size=5\n",
    "for cpd in model.get_cpds():\n",
    "\n",
    "  print(cpd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
