{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prove that map-reduced version of correlation function is within 0.5% of non-mapreduced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as ss\n",
    "np.random.seed(42)\n",
    "from collections import Counter\n",
    "from multiprocessing import Pool, cpu_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base Correlation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conditional_entropy(x, y):\n",
    "    \"\"\"Calculates the conditional entropy of x given y: S(x|y)\n",
    "    Wikipedia: https://en.wikipedia.org/wiki/Conditional_entropy\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : array-like\n",
    "        A sequence of measurements.\n",
    "    y : array-like\n",
    "        A sequence of measurements.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The total entropy of x given y\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> np.random.seed(1)\n",
    "    >>> x = np.random.randint(0,2, size=10)\n",
    "    >>> y = np.random.randint(0,2, size=10)\n",
    "    >>> conditional_entropy(x,y)\n",
    "    0.606842558824411\n",
    "\n",
    "    \"\"\"\n",
    "    y_counter = Counter(y)\n",
    "    xy_counter = Counter(list(zip(x, y)))\n",
    "    total_occurrences = sum(y_counter.values())\n",
    "    p_xy = np.array([val for val in xy_counter.values()])/total_occurrences\n",
    "    p_y = np.array([y_counter[xy[1]] for xy in xy_counter.keys()])/total_occurrences\n",
    "    entropy = np.sum((p_xy * np.log(p_y/p_xy)))\n",
    "    return entropy\n",
    "\n",
    "\n",
    "def cramers_v(x, y):\n",
    "    \"\"\"Calculates Cramer's V statistic for categorical-categorical association.\n",
    "    Uses correction from Bergsma and Wicher, Journal of the Korean Statistical Society 42 (2013): 323-328.\n",
    "    This is a symmetric coefficient: V(x,y) = V(y,x)\n",
    "    Original function taken from: https://stackoverflow.com/a/46498792/5863503\n",
    "    Wikipedia: https://en.wikipedia.org/wiki/Cram%C3%A9r%27s_V\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : array-like\n",
    "        A sequence of categorical measurements.\n",
    "    y : array-like\n",
    "        A sequence of categorical measurements.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Coefficient in the range [0, 1].\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> np.random.seed(1)\n",
    "    >>> x = np.random.randint(0, 2, size=100)\n",
    "    >>> y = x\n",
    "    >>> cramers_v(x, y)\n",
    "    0.9795896894087645\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    confusion_matrix = pd.crosstab(x, y)\n",
    "    chi2 = ss.chi2_contingency(confusion_matrix)[0]\n",
    "    n = confusion_matrix.sum().sum()\n",
    "    phi2 = chi2/n\n",
    "    r, k = confusion_matrix.shape\n",
    "    phi2corr = max(0, phi2-((k-1)*(r-1))/(n-1))\n",
    "    rcorr = r-((r-1)**2)/(n-1)\n",
    "    kcorr = k-((k-1)**2)/(n-1)\n",
    "    return np.sqrt(phi2corr/min((kcorr-1), (rcorr-1)))\n",
    "\n",
    "\n",
    "def theils_u(x, y):\n",
    "    \"\"\"Calculates Theil's U statistic (Uncertainty coefficient) for categorical-categorical association.\n",
    "    This is the uncertainty of x given y: value is on the range of [0,1] - where 0 means y provides no information about\n",
    "    x, and 1 means y provides full information about x.\n",
    "    Given the value of x, how many possible states does y have, and how often do they occur.\n",
    "    This is an asymmetric coefficient: U(x,y) != U(y,x)\n",
    "    Wikipedia: https://en.wikipedia.org/wiki/Uncertainty_coefficient\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : array-like\n",
    "        A sequence of categorical measurements.\n",
    "    y : array-like\n",
    "        A sequence of categorical measurements.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Coefficient in the range [0, 1].\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> np.random.seed(1)\n",
    "    >>> x = np.random.randint(0, 2, size=100)\n",
    "    >>> y = x\n",
    "    >>> theils_u(x, y)\n",
    "    1.0\n",
    "\n",
    "    \"\"\"\n",
    "    s_xy = conditional_entropy(x, y)\n",
    "    x_counter = Counter(x)\n",
    "    total_occurrences = sum(x_counter.values())\n",
    "    p_x = list(map(lambda n: n/total_occurrences, x_counter.values()))\n",
    "    s_x = ss.entropy(p_x)\n",
    "    if s_x == 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return (s_x - s_xy) / s_x\n",
    "\n",
    "\n",
    "def correlation_ratio(categories, measurements):\n",
    "    \"\"\"Calculates the Correlation Ratio (sometimes marked by the greek letter Eta) for categorical-continuous association.\n",
    "    Answers the question - given a continuous value of a measurement, is it possible to know which category is it\n",
    "    associated with?\n",
    "    Value is in the range [0,1], where 0 means a category cannot be determined by a continuous measurement, and 1 means\n",
    "    a category can be determined with absolute certainty.\n",
    "    Wikipedia: https://en.wikipedia.org/wiki/Correlation_ratio\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    categories : array-like\n",
    "        A sequence of categorical measurements.\n",
    "    measurements : array-like\n",
    "        A sequence of continuous measurements.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Coefficient in the range [0, 1].\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> np.random.seed(1)\n",
    "    >>> categories = np.random.randint(0,2, size=100)\n",
    "    >>> measurements = np.random.rand(100)\n",
    "    >>> correlation_ratio(categories, measurements)\n",
    "    0.042988734885557815\n",
    "\n",
    "    \"\"\"\n",
    "    fcat, _ = pd.factorize(categories)\n",
    "    cat_num = np.max(fcat)+1\n",
    "    y_avg_array = np.zeros(cat_num)\n",
    "    n_array = np.zeros(cat_num)\n",
    "    for i in range(0, cat_num):\n",
    "        cat_measures = measurements[np.argwhere(fcat == i).flatten()]\n",
    "        n_array[i] = len(cat_measures)\n",
    "        y_avg_array[i] = np.average(cat_measures)\n",
    "    y_total_avg = np.sum(np.multiply(y_avg_array, n_array))/np.sum(n_array)\n",
    "    numerator = np.sum(np.multiply(n_array, np.power(np.subtract(y_avg_array, y_total_avg), 2)))\n",
    "    denominator = np.sum(np.power(np.subtract(measurements, y_total_avg), 2))\n",
    "    if numerator == 0:\n",
    "        eta = 0.0\n",
    "    else:\n",
    "        eta = numerator/denominator\n",
    "    return eta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simul_parallel(func, x, y, n=100):\n",
    "    res = []\n",
    "    beg = 0\n",
    "    end = 0\n",
    "    increment = len(x)//n\n",
    "    for i in range(int(n)):\n",
    "        end += increment\n",
    "        if (len(x) - end) < increment:\n",
    "            end = None\n",
    "        res.append(func(x[beg:end], y[beg:end]))\n",
    "        beg = end\n",
    "\n",
    "    return np.mean(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallel_trials(func, x, y, Ns):\n",
    "    # Simulate Results of Chunk step in Dask ACA\n",
    "    \"\"\"\n",
    "    Call simul_parallel in parallel (utilize multiple CPUs), each call takes:\n",
    "        * func - a function to apply\n",
    "        * x - data, array\n",
    "        * y - data, array\n",
    "        * n - chunk size\n",
    "    func is applied to chunks (of size n) of arrays x and y. The results of func applied to\n",
    "    each chunk are averaged and returned. \n",
    "    \"\"\"\n",
    "    with Pool(cpu_count()-1) as pool:\n",
    "        res = pool.starmap(simul_parallel, [(func,x,y,n) for n in Ns])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_diff_from_trials(func, x, y, Ns):\n",
    "    func_ser = func(x,y)\n",
    "    func_par = parallel_trials(func, x, y, Ns)\n",
    "    max_diff = (np.abs(np.array(func_par)-func_ser)/func_ser).max()\n",
    "    return max_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Demo Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = np.arange(2)\n",
    "size = 1000000\n",
    "cats_1 = np.random.choice(cats, size=size)\n",
    "cats_2 = np.array([x if np.random.uniform()< .9 else (x+1)%len(cats) for x in cats_1])\n",
    "conts_1 = np.array([np.random.randn()+.5 if x else np.random.randn()-.5 for x in cats_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ns = np.logspace(1,3, num=10, dtype=int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cramers V Parallel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cramers_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7998418887727863"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cramer_ser = cramers_v(cats_1, cats_2)\n",
    "cramer_ser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "cramer_max_diff = get_max_diff_from_trials(cramers_v, cats_1, cats_2, Ns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Within 0.5% "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.27997057669525616\n"
     ]
    }
   ],
   "source": [
    "print(cramer_max_diff*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Theils_U Parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5318704426953134"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theils_ser = theils_u(cats_1, cats_2)\n",
    "theils_ser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "theils_max_diff = get_max_diff_from_trials(theils_u, cats_1, cats_2, Ns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Within 0.5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21295064331663247\n"
     ]
    }
   ],
   "source": [
    "print(theils_max_diff*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation Coefficient Parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20028934064832624"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eta_ser = correlation_ratio(cats_1, conts_1)\n",
    "eta_ser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta_max_diff = get_max_diff_from_trials(correlation_ratio, cats_1, conts_1, Ns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Within 0.5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24989565669311598\n"
     ]
    }
   ],
   "source": [
    "print(eta_max_diff*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even with small partitions, the ACA style aggregation of the correlations will yield results within +- 0.5% which is more than acceptable tolerance for our purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
